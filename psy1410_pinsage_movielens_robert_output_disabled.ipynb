{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "psy1410_pinsage_movielens_robert_output_disabled.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "GC1qSLvsaPa8",
        "8pHlevgQNa5r",
        "ZUgjyg8fODIe",
        "vL-U9yVKOWRq",
        "kJCRXSOFOuMg",
        "iZ88V0E6OzT1",
        "VcaEj78dClg4",
        "dG8ufOynCZAL",
        "wskjzTovL0pU"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMOLfHoQj462b8CvvQM0H/g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harvard-visionlab/psy1410/blob/master/psy1410_pinsage_movielens_robert_output_disabled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJs5ps37MA94"
      },
      "source": [
        "# PinSage MovieRecommendation\n",
        "\n",
        "This notebook has code that can be used to use PinSage for an \"implicit recommender task.\" In this case, the data are Movie Rating, so you are data are users and ratings for some set of movies. The data are split into a training and test set, and the goal is to learn representations of users/movies that enable you to recommend movies a person would actually watch. You check the quality of your recommendtions by using the \"test data\" to see if they actually already watched any of the movies you recommended. Specifically, you measure what percentage of your \"top10 ratings\" are \"hits\" (movies they actually watched, i.e., movies in the test set that they have arated). \n",
        "\n",
        "To get started.\n",
        "0. Goto \"Runtime\"=>\"Change runtime type\" and make sure you are using the GPU, and that you uncheck \"Omit code cell output when saving this notebook\" so that cell-outputs will be saved in the file. (When I save notebooks to github, I exclude the cell outputs because the file is then smaller).\n",
        "1. Run the \"PinSage Prep\" section (~5-10min). \n",
        "2. Run the \"PinSage Code\" section\n",
        "3. Open up the \"Check the model with data\" section to see what the PinSage model looks like\n",
        "4. Goto the section \"PinSage Train on Implicit Task\" and run the \"baseline model, movie id only\" section. This is the minimal model, and only tries to learn an embedding for movies without any extra information about the movies. This will be your \"baseline model\" and the critical question is whether adding more information (e.g., plot embeddings, poster embeddings), or changing hyperparameters improves the model's performance. (~90 min)\n",
        "5. Choose 1 more of the suggested \"possible variations\" to run and see what factors influence the model's performance.\n",
        "6. Writeup a brief Summary & Conclusions of your work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC1qSLvsaPa8"
      },
      "source": [
        "# PinSage Prep \n",
        "\n",
        "This Chunk downloads and pre-processes moviedata, preparing the graphs training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij80RdOLMtQA"
      },
      "source": [
        "!pip install dgl-cu101 --upgrade\n",
        "!python -m pip install dask[dataframe] --upgrade\n",
        "!pip install madgrad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZrT_CQ3NKm6"
      },
      "source": [
        "!wget -c http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
        "!unzip ml-1m.zip\n",
        "!rm ml-1m.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WleQzrk7SySg"
      },
      "source": [
        "!wget -c https://www.dropbox.com/s/4blru88qafx1i4l/ml_25m_tmdb_plot_paraphrase-distilroberta-base-v1.pth.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao_O2Q43otDk"
      },
      "source": [
        "!wget --quiet -c https://www.dropbox.com/s/8ty0mis0u3eza45/tmdb_backdrops_w780_SwinTransformer_avgpool.pth.tar\n",
        "!wget --quiet -c https://www.dropbox.com/s/rrovh5ludxonzxs/tmdb_backdrops_w780_VGG_classifier.4.pth.tar\n",
        "!wget --quiet -c https://www.dropbox.com/s/ixfo4yxq58utj9c/tmdb_posters_w500_VGG_classifier.4.pth.tar\n",
        "!wget --quiet -c https://www.dropbox.com/s/u5akhzatpmrck3a/tmdb_posters_w500_SwinTransformer_avgpool.pth.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe4hCqzfXjLs"
      },
      "source": [
        "!wget --quiet -c https://www.dropbox.com/s/qeur875d23zivko/ml_25m_links_imdb_synopsis_paraphrase-distilroberta-base-v1.pth.tar\n",
        "!wget --quiet -c https://www.dropbox.com/s/vpi2uno5plp2kvd/ml_25m_links_imdb_plot_paraphrase-distilroberta-base-v1.pth.tar\n",
        "!wget --quiet -c https://www.dropbox.com/s/wrwcprh2wih7rz5/ml_25m_links_imdb_longest_paraphrase-distilroberta-base-v1.pth.tar\n",
        "!wget --quiet -c https://www.dropbox.com/s/dgsom5hcdxjn8rs/ml_25m_links_imdb_full_plot_paraphrase-distilroberta-base-v1.pth.tar\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDpTpeEpcVU2"
      },
      "source": [
        "\"\"\"Graph builder from pandas dataframes\"\"\"\n",
        "from collections import namedtuple\n",
        "from pandas.api.types import is_numeric_dtype, is_categorical_dtype, is_categorical\n",
        "import dgl\n",
        "\n",
        "__all__ = ['PandasGraphBuilder']\n",
        "\n",
        "def _series_to_tensor(series):\n",
        "    if is_categorical(series):\n",
        "        return torch.LongTensor(series.cat.codes.values.astype('int64'))\n",
        "    else:       # numeric\n",
        "        return torch.FloatTensor(series.values)\n",
        "\n",
        "class PandasGraphBuilder(object):\n",
        "    \"\"\"Creates a heterogeneous graph from multiple pandas dataframes.\n",
        "    Examples\n",
        "    --------\n",
        "    Let's say we have the following three pandas dataframes:\n",
        "    User table ``users``:\n",
        "    ===========  ===========  =======\n",
        "    ``user_id``  ``country``  ``age``\n",
        "    ===========  ===========  =======\n",
        "    XYZZY        U.S.         25\n",
        "    FOO          China        24\n",
        "    BAR          China        23\n",
        "    ===========  ===========  =======\n",
        "    Game table ``games``:\n",
        "    ===========  =========  ==============  ==================\n",
        "    ``game_id``  ``title``  ``is_sandbox``  ``is_multiplayer``\n",
        "    ===========  =========  ==============  ==================\n",
        "    1            Minecraft  True            True\n",
        "    2            Tetris 99  False           True\n",
        "    ===========  =========  ==============  ==================\n",
        "    Play relationship table ``plays``:\n",
        "    ===========  ===========  =========\n",
        "    ``user_id``  ``game_id``  ``hours``\n",
        "    ===========  ===========  =========\n",
        "    XYZZY        1            24\n",
        "    FOO          1            20\n",
        "    FOO          2            16\n",
        "    BAR          2            28\n",
        "    ===========  ===========  =========\n",
        "    One could then create a bidirectional bipartite graph as follows:\n",
        "    >>> builder = PandasGraphBuilder()\n",
        "    >>> builder.add_entities(users, 'user_id', 'user')\n",
        "    >>> builder.add_entities(games, 'game_id', 'game')\n",
        "    >>> builder.add_binary_relations(plays, 'user_id', 'game_id', 'plays')\n",
        "    >>> builder.add_binary_relations(plays, 'game_id', 'user_id', 'played-by')\n",
        "    >>> g = builder.build()\n",
        "    >>> g.number_of_nodes('user')\n",
        "    3\n",
        "    >>> g.number_of_edges('plays')\n",
        "    4\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.entity_tables = {}\n",
        "        self.relation_tables = {}\n",
        "\n",
        "        self.entity_pk_to_name = {}     # mapping from primary key name to entity name\n",
        "        self.entity_pk = {}             # mapping from entity name to primary key\n",
        "        self.entity_key_map = {}        # mapping from entity names to primary key values\n",
        "        self.num_nodes_per_type = {}\n",
        "        self.edges_per_relation = {}\n",
        "        self.relation_name_to_etype = {}\n",
        "        self.relation_src_key = {}      # mapping from relation name to source key\n",
        "        self.relation_dst_key = {}      # mapping from relation name to destination key\n",
        "\n",
        "    def add_entities(self, entity_table, primary_key, name):        \n",
        "        entities = entity_table[primary_key].astype('category')\n",
        "        #set_trace()\n",
        "\n",
        "        #if not entity_table[primary_key].is_unique:\n",
        "        if not (entities.value_counts() == 1).all():                \n",
        "            raise ValueError('Different entity with the same primary key detected.')\n",
        "        \n",
        "        # preserve the category order in the original entity table\n",
        "        entities = entities.cat.reorder_categories(entity_table[primary_key].values)\n",
        "\n",
        "        self.entity_pk_to_name[primary_key] = name\n",
        "        self.entity_pk[name] = primary_key\n",
        "        self.num_nodes_per_type[name] = entity_table.shape[0]\n",
        "        #self.num_nodes_per_type[name] = len(entities.cat.categories)\n",
        "        self.entity_key_map[name] = entities\n",
        "        self.entity_tables[name] = entity_table\n",
        "\n",
        "    def add_binary_relations(self, relation_table, source_key, destination_key, name):\n",
        "        src = relation_table[source_key].astype('category')\n",
        "        src = src.cat.set_categories(\n",
        "            self.entity_key_map[self.entity_pk_to_name[source_key]].cat.categories)\n",
        "        dst = relation_table[destination_key].astype('category')\n",
        "        dst = dst.cat.set_categories(\n",
        "            self.entity_key_map[self.entity_pk_to_name[destination_key]].cat.categories)\n",
        "        if src.isnull().any():\n",
        "            raise ValueError(\n",
        "                'Some source entities in relation %s do not exist in entity %s.' %\n",
        "                (name, source_key))\n",
        "        if dst.isnull().any():\n",
        "            raise ValueError(\n",
        "                'Some destination entities in relation %s do not exist in entity %s.' %\n",
        "                (name, destination_key))\n",
        "\n",
        "        srctype = self.entity_pk_to_name[source_key]\n",
        "        dsttype = self.entity_pk_to_name[destination_key]\n",
        "        etype = (srctype, name, dsttype)\n",
        "        self.relation_name_to_etype[name] = etype\n",
        "        self.edges_per_relation[etype] = (src.cat.codes.values.astype('int64'), dst.cat.codes.values.astype('int64'))\n",
        "        self.relation_tables[name] = relation_table\n",
        "        self.relation_src_key[name] = source_key\n",
        "        self.relation_dst_key[name] = destination_key\n",
        "\n",
        "    def build(self):\n",
        "        # Create heterograph\n",
        "        graph = dgl.heterograph(self.edges_per_relation, self.num_nodes_per_type)\n",
        "        return graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px94qkFYMHG_"
      },
      "source": [
        "\"\"\"\n",
        "Script that reads from raw MovieLens-1M data and dumps into a pickle\n",
        "file the following:\n",
        "* A heterogeneous graph with categorical features.\n",
        "* A list with all the movie titles.  The movie titles correspond to\n",
        "  the movie nodes in the heterogeneous graph.\n",
        "This script exemplifies how to prepare tabular data with textual\n",
        "features.  Since DGL graphs do not store variable-length features, we\n",
        "instead put variable-length features into a more suitable container\n",
        "(e.g. torchtext to handle list of texts)\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import argparse\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.sparse as ssp\n",
        "import dgl\n",
        "import torch\n",
        "import torchtext\n",
        "#from builder import PandasGraphBuilder\n",
        "\n",
        "import torch\n",
        "import dgl\n",
        "import numpy as np\n",
        "import scipy.sparse as ssp\n",
        "import tqdm\n",
        "import dask.dataframe as dd\n",
        "\n",
        "# This is the train-test split method most of the recommender system papers running on MovieLens\n",
        "# takes.  It essentially follows the intuition of \"training on the past and predict the future\".\n",
        "# One can also change the threshold to make validation and test set take larger proportions.\n",
        "def train_test_split_by_time(df, timestamp, user):\n",
        "    df['train_mask'] = np.ones((len(df),), dtype=np.bool)\n",
        "    df['val_mask'] = np.zeros((len(df),), dtype=np.bool)\n",
        "    df['test_mask'] = np.zeros((len(df),), dtype=np.bool)\n",
        "    df = dd.from_pandas(df, npartitions=10)\n",
        "    def train_test_split(df):\n",
        "        df = df.sort_values([timestamp])\n",
        "        if df.shape[0] > 1:\n",
        "            df.iloc[-1, -3] = False\n",
        "            df.iloc[-1, -1] = True\n",
        "        if df.shape[0] > 2:\n",
        "            df.iloc[-2, -3] = False\n",
        "            df.iloc[-2, -2] = True\n",
        "        return df\n",
        "    df = df.groupby(user, group_keys=False).apply(train_test_split).compute(scheduler='processes').sort_index()\n",
        "    print(df[df[user] == df[user].unique()[0]].sort_values(timestamp))\n",
        "    return df['train_mask'].to_numpy().nonzero()[0], \\\n",
        "           df['val_mask'].to_numpy().nonzero()[0], \\\n",
        "           df['test_mask'].to_numpy().nonzero()[0]\n",
        "\n",
        "def build_train_graph(g, train_indices, utype, itype, etype, etype_rev):\n",
        "    train_g = g.edge_subgraph(\n",
        "        {etype: train_indices, etype_rev: train_indices},\n",
        "        preserve_nodes=True)\n",
        "    # remove the induced node IDs - should be assigned by model instead\n",
        "    del train_g.nodes[utype].data[dgl.NID]\n",
        "    del train_g.nodes[itype].data[dgl.NID]\n",
        "\n",
        "    # copy features\n",
        "    for ntype in g.ntypes:\n",
        "        for col, data in g.nodes[ntype].data.items():\n",
        "            train_g.nodes[ntype].data[col] = data\n",
        "    for etype in g.etypes:\n",
        "        for col, data in g.edges[etype].data.items():\n",
        "            train_g.edges[etype].data[col] = data[train_g.edges[etype].data[dgl.EID]]\n",
        "\n",
        "    return train_g\n",
        "\n",
        "def build_val_test_matrix(g, val_indices, test_indices, utype, itype, etype):\n",
        "    n_users = g.number_of_nodes(utype)\n",
        "    n_items = g.number_of_nodes(itype)\n",
        "    val_src, val_dst = g.find_edges(val_indices, etype=etype)\n",
        "    test_src, test_dst = g.find_edges(test_indices, etype=etype)\n",
        "    val_src = val_src.numpy()\n",
        "    val_dst = val_dst.numpy()\n",
        "    test_src = test_src.numpy()\n",
        "    test_dst = test_dst.numpy()\n",
        "    val_matrix = ssp.coo_matrix((np.ones_like(val_src), (val_src, val_dst)), (n_users, n_items))\n",
        "    test_matrix = ssp.coo_matrix((np.ones_like(test_src), (test_src, test_dst)), (n_users, n_items))\n",
        "\n",
        "    return val_matrix, test_matrix\n",
        "\n",
        "def linear_normalize(values):\n",
        "    return (values - values.min(0, keepdims=True)) / \\\n",
        "        (values.max(0, keepdims=True) - values.min(0, keepdims=True))\n",
        "\n",
        "def process_movielens1m(directory, output_path):\n",
        "\n",
        "    ## Build heterogeneous graph\n",
        "    \n",
        "    # Load data\n",
        "    users = []\n",
        "    with open(os.path.join(directory, 'users.dat'), encoding='latin1') as f:\n",
        "        for l in f:\n",
        "            id_, gender, age, occupation, zip_ = l.strip().split('::')\n",
        "            users.append({\n",
        "                'user_id': int(id_),\n",
        "                'gender': gender,\n",
        "                'age': age,\n",
        "                'occupation': occupation,\n",
        "                'zip': zip_,\n",
        "                })\n",
        "    users = pd.DataFrame(users).astype('category')\n",
        "\n",
        "    movies = []\n",
        "    with open(os.path.join(directory, 'movies.dat'), encoding='latin1') as f:\n",
        "        for l in f:\n",
        "            id_, title, genres = l.strip().split('::')\n",
        "            genres_set = set(genres.split('|'))\n",
        "\n",
        "            # extract year\n",
        "            assert re.match(r'.*\\([0-9]{4}\\)$', title)\n",
        "            year = title[-5:-1]\n",
        "            title = title[:-6].strip()\n",
        "\n",
        "            data = {'movie_id': int(id_), 'title': title, 'year': year}\n",
        "            for g in genres_set:\n",
        "                data[g] = True\n",
        "            movies.append(data)\n",
        "    movies = pd.DataFrame(movies).astype({'year': 'category'})\n",
        "\n",
        "    ratings = []\n",
        "    with open(os.path.join(directory, 'ratings.dat'), encoding='latin1') as f:\n",
        "        for l in f:\n",
        "            user_id, movie_id, rating, timestamp = [int(_) for _ in l.split('::')]\n",
        "            ratings.append({\n",
        "                'user_id': user_id,\n",
        "                'movie_id': movie_id,\n",
        "                'rating': rating,\n",
        "                'timestamp': timestamp,\n",
        "                })\n",
        "    ratings = pd.DataFrame(ratings)\n",
        "\n",
        "    # Filter the users and items that never appear in the rating table.\n",
        "    distinct_users_in_ratings = ratings['user_id'].unique()\n",
        "    distinct_movies_in_ratings = ratings['movie_id'].unique()\n",
        "    users = users[users['user_id'].isin(distinct_users_in_ratings)]\n",
        "    movies = movies[movies['movie_id'].isin(distinct_movies_in_ratings)]\n",
        "\n",
        "    # Group the movie features into genres (a vector), year (a category), title (a string)\n",
        "    genre_columns = movies.columns.drop(['movie_id', 'title', 'year'])\n",
        "    movies[genre_columns] = movies[genre_columns].fillna(False).astype('bool')\n",
        "    movies_categorical = movies.drop('title', axis=1)\n",
        "\n",
        "    # Build graph\n",
        "    graph_builder = PandasGraphBuilder()\n",
        "    graph_builder.add_entities(users, 'user_id', 'user')\n",
        "    graph_builder.add_entities(movies_categorical, 'movie_id', 'movie')\n",
        "    graph_builder.add_binary_relations(ratings, 'user_id', 'movie_id', 'watched')\n",
        "    graph_builder.add_binary_relations(ratings, 'movie_id', 'user_id', 'watched-by')\n",
        "\n",
        "    g = graph_builder.build()\n",
        "\n",
        "    # Assign features.\n",
        "    # Note that variable-sized features such as texts or images are handled elsewhere.\n",
        "    g.nodes['user'].data['gender'] = torch.LongTensor(users['gender'].cat.codes.values)\n",
        "    g.nodes['user'].data['age'] = torch.LongTensor(users['age'].cat.codes.values)\n",
        "    g.nodes['user'].data['occupation'] = torch.LongTensor(users['occupation'].cat.codes.values)\n",
        "    g.nodes['user'].data['zip'] = torch.LongTensor(users['zip'].cat.codes.values)\n",
        "\n",
        "    g.nodes['movie'].data['year'] = torch.LongTensor(movies['year'].cat.codes.values)\n",
        "    g.nodes['movie'].data['genre'] = torch.FloatTensor(movies[genre_columns].values)\n",
        "\n",
        "    g.edges['watched'].data['rating'] = torch.LongTensor(ratings['rating'].values)\n",
        "    g.edges['watched'].data['timestamp'] = torch.LongTensor(ratings['timestamp'].values)\n",
        "    g.edges['watched-by'].data['rating'] = torch.LongTensor(ratings['rating'].values)\n",
        "    g.edges['watched-by'].data['timestamp'] = torch.LongTensor(ratings['timestamp'].values)\n",
        "\n",
        "    # Train-validation-test split\n",
        "    # This is a little bit tricky as we want to select the last interaction for test, and the\n",
        "    # second-to-last interaction for validation.\n",
        "    train_indices, val_indices, test_indices = train_test_split_by_time(ratings, 'timestamp', 'user_id')\n",
        "\n",
        "    # Build the graph with training interactions only.\n",
        "    train_g = build_train_graph(g, train_indices, 'user', 'movie', 'watched', 'watched-by')\n",
        "    assert train_g.out_degrees(etype='watched').min() > 0\n",
        "\n",
        "    # Build the user-item sparse matrix for validation and test set.\n",
        "    val_matrix, test_matrix = build_val_test_matrix(g, val_indices, test_indices, 'user', 'movie', 'watched')\n",
        "\n",
        "    ## Build title set\n",
        "\n",
        "    movie_textual_dataset = {'title': movies['title'].values}\n",
        "\n",
        "    # The model should build their own vocabulary and process the texts.  Here is one example\n",
        "    # of using torchtext to pad and numericalize a batch of strings.\n",
        "    #     field = torchtext.data.Field(include_lengths=True, lower=True, batch_first=True)\n",
        "    #     examples = [torchtext.data.Example.fromlist([t], [('title', title_field)]) for t in texts]\n",
        "    #     titleset = torchtext.data.Dataset(examples, [('title', title_field)])\n",
        "    #     field.build_vocab(titleset.title, vectors='fasttext.simple.300d')\n",
        "    #     token_ids, lengths = field.process([examples[0].title, examples[1].title])\n",
        "\n",
        "    ## Dump the graph and the datasets\n",
        "\n",
        "    dataset = {\n",
        "        'train-graph': train_g,\n",
        "        'val-matrix': val_matrix,\n",
        "        'test-matrix': test_matrix,\n",
        "        'item-texts': movie_textual_dataset,\n",
        "        'item-images': None,\n",
        "        'user-type': 'user',\n",
        "        'item-type': 'movie',\n",
        "        'user-to-item-type': 'watched',\n",
        "        'item-to-user-type': 'watched-by',\n",
        "        'timestamp-edge-column': 'timestamp'}\n",
        "\n",
        "    with open(output_path, 'wb') as f:\n",
        "        pickle.dump(dataset, f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSwUHFXPTp4B"
      },
      "source": [
        "from IPython.core.debugger import set_trace \n",
        "from fastprogress.fastprogress import progress_bar\n",
        "\n",
        "def process_movielens1m_text(directory, output_path, text_embeddings,\n",
        "                             only_id=False):\n",
        "\n",
        "    ## Build heterogeneous graph\n",
        "\n",
        "    # Load plot embeddings\n",
        "    embeddings = torch.load(text_embeddings, map_location='cpu')\n",
        "\n",
        "    # Load data\n",
        "    users = []\n",
        "    with open(os.path.join(directory, 'users.dat'), encoding='latin1') as f:\n",
        "        for l in f:\n",
        "            id_, gender, age, occupation, zip_ = l.strip().split('::')\n",
        "            users.append({\n",
        "                'user_id': int(id_),\n",
        "                'gender': gender,\n",
        "                'age': age,\n",
        "                'occupation': occupation,\n",
        "                'zip': zip_,\n",
        "                })\n",
        "    users = pd.DataFrame(users).astype('category')\n",
        "\n",
        "    movies = []\n",
        "    with open(os.path.join(directory, 'movies.dat'), encoding='latin1') as f:\n",
        "        for l in f:\n",
        "            id_, title, genres = l.strip().split('::')\n",
        "            genres_set = set(genres.split('|'))\n",
        "\n",
        "            # extract year\n",
        "            assert re.match(r'.*\\([0-9]{4}\\)$', title)\n",
        "            year = title[-5:-1]\n",
        "            title = title[:-6].strip()\n",
        "\n",
        "            data = {'movie_id': int(id_), 'title': title, 'year': year}\n",
        "            for g in genres_set:\n",
        "                data[g] = True\n",
        "            movies.append(data)\n",
        "    movies = pd.DataFrame(movies).astype({'year': 'category'})\n",
        "\n",
        "    ratings = []\n",
        "    with open(os.path.join(directory, 'ratings.dat'), encoding='latin1') as f:\n",
        "        for l in f:\n",
        "            user_id, movie_id, rating, timestamp = [int(_) for _ in l.split('::')]\n",
        "            ratings.append({\n",
        "                'user_id': user_id,\n",
        "                'movie_id': movie_id,\n",
        "                'rating': rating,\n",
        "                'timestamp': timestamp,\n",
        "                })\n",
        "    ratings = pd.DataFrame(ratings)\n",
        "\n",
        "    # Filter the users and items that never appear in the rating table.    \n",
        "    distinct_users_in_ratings = ratings['user_id'].unique()\n",
        "    distinct_movies_in_ratings = ratings['movie_id'].unique()\n",
        "    users = users[users['user_id'].isin(distinct_users_in_ratings)]\n",
        "    movies = movies[movies['movie_id'].isin(distinct_movies_in_ratings)]\n",
        "\n",
        "    # Filter users and items for movies that don't have embeddings\n",
        "    distinct_movies = movies['movie_id'].unique()\n",
        "\n",
        "    # drop embeddings for movies not in set\n",
        "    distinct_movies_with_embeddings = np.array(embeddings['ml_ids'])    \n",
        "    embedding_has_rating = np.in1d(distinct_movies_with_embeddings, distinct_movies)\n",
        "    distinct_movies_with_embeddings = distinct_movies_with_embeddings[embedding_has_rating]\n",
        "\n",
        "    # drop movies without embedding\n",
        "    movie_has_embedding = np.in1d(distinct_movies, distinct_movies_with_embeddings)\n",
        "    rated_movies_with_embeddings = distinct_movies[movie_has_embedding]\n",
        "\n",
        "    # Filter ratings, users, movies\n",
        "    ratings = ratings[ratings['movie_id'].isin(rated_movies_with_embeddings)]\n",
        "    distinct_users_in_ratings = ratings['user_id'].unique()\n",
        "    distinct_movies_in_ratings = ratings['movie_id'].unique()\n",
        "    #filtering users breaks everything, do don't\n",
        "    #users = users[users['user_id'].isin(distinct_users_in_ratings)]\n",
        "    movies = movies[movies['movie_id'].isin(distinct_movies_in_ratings)]        \n",
        "\n",
        "    # align the plot data with the movies dataframe\n",
        "    # use_embeddings = np.in1d(np.array(embeddings['ml_ids']), movies['movie_id'].unique())\n",
        "    plot_data = []\n",
        "    for r,movie in progress_bar(movies.iterrows(), total=len(movies)):\n",
        "      idx = embeddings['ml_ids'].index(movie.movie_id)\n",
        "      plot_data.append(embeddings['embedding'][idx])\n",
        "\n",
        "    # Group the movie features into genres (a vector), year (a category), title (a string)\n",
        "    genre_columns = movies.columns.drop(['movie_id', 'title', 'year'])\n",
        "    movies[genre_columns] = movies[genre_columns].fillna(False).astype('bool')\n",
        "    movies_categorical = movies.drop('title', axis=1)    \n",
        "\n",
        "    # Build graph\n",
        "    graph_builder = PandasGraphBuilder()\n",
        "    graph_builder.add_entities(users, 'user_id', 'user')\n",
        "    graph_builder.add_entities(movies_categorical, 'movie_id', 'movie')\n",
        "    graph_builder.add_binary_relations(ratings, 'user_id', 'movie_id', 'watched')\n",
        "    graph_builder.add_binary_relations(ratings, 'movie_id', 'user_id', 'watched-by')\n",
        "\n",
        "    g = graph_builder.build()\n",
        "\n",
        "    # Assign features.\n",
        "    # Note that variable-sized features such as texts or images are handled elsewhere.\n",
        "    g.nodes['user'].data['gender'] = torch.LongTensor(users['gender'].cat.codes.values)\n",
        "    g.nodes['user'].data['age'] = torch.LongTensor(users['age'].cat.codes.values)\n",
        "    g.nodes['user'].data['occupation'] = torch.LongTensor(users['occupation'].cat.codes.values)\n",
        "    g.nodes['user'].data['zip'] = torch.LongTensor(users['zip'].cat.codes.values)\n",
        "\n",
        "    if only_id==False:\n",
        "      g.nodes['movie'].data['year'] = torch.LongTensor(movies['year'].cat.codes.values)\n",
        "      g.nodes['movie'].data['genre'] = torch.FloatTensor(movies[genre_columns].values)    \n",
        "      g.nodes['movie'].data['plot'] = torch.stack(plot_data)\n",
        "    \n",
        "    g.edges['watched'].data['rating'] = torch.LongTensor(ratings['rating'].values)\n",
        "    g.edges['watched'].data['timestamp'] = torch.LongTensor(ratings['timestamp'].values)\n",
        "    g.edges['watched-by'].data['rating'] = torch.LongTensor(ratings['rating'].values)\n",
        "    g.edges['watched-by'].data['timestamp'] = torch.LongTensor(ratings['timestamp'].values)\n",
        "\n",
        "    # Train-validation-test split\n",
        "    # This is a little bit tricky as we want to select the last interaction for test, and the\n",
        "    # second-to-last interaction for validation.\n",
        "    train_indices, val_indices, test_indices = train_test_split_by_time(ratings, 'timestamp', 'user_id')\n",
        "\n",
        "    # Build the graph with training interactions only.\n",
        "    train_g = build_train_graph(g, train_indices, 'user', 'movie', 'watched', 'watched-by')\n",
        "    assert train_g.out_degrees(etype='watched').min() > 0\n",
        "\n",
        "    # Build the user-item sparse matrix for validation and test set.\n",
        "    val_matrix, test_matrix = build_val_test_matrix(g, val_indices, test_indices, 'user', 'movie', 'watched')\n",
        "\n",
        "    ## Build title set\n",
        "\n",
        "    movie_textual_dataset = {'title': movies['title'].values}\n",
        "\n",
        "    # The model should build their own vocabulary and process the texts.  Here is one example\n",
        "    # of using torchtext to pad and numericalize a batch of strings.\n",
        "    #     field = torchtext.data.Field(include_lengths=True, lower=True, batch_first=True)\n",
        "    #     examples = [torchtext.data.Example.fromlist([t], [('title', title_field)]) for t in texts]\n",
        "    #     titleset = torchtext.data.Dataset(examples, [('title', title_field)])\n",
        "    #     field.build_vocab(titleset.title, vectors='fasttext.simple.300d')\n",
        "    #     token_ids, lengths = field.process([examples[0].title, examples[1].title])\n",
        "\n",
        "    ## Dump the graph and the datasets\n",
        "\n",
        "    dataset = {\n",
        "        'train-graph': train_g,\n",
        "        'val-matrix': val_matrix,\n",
        "        'test-matrix': test_matrix,\n",
        "        'item-texts': movie_textual_dataset,\n",
        "        'item-images': None,\n",
        "        'user-type': 'user',\n",
        "        'item-type': 'movie',\n",
        "        'user-to-item-type': 'watched',\n",
        "        'item-to-user-type': 'watched-by',\n",
        "        'timestamp-edge-column': 'timestamp'}\n",
        "\n",
        "    with open(output_path, 'wb') as f:\n",
        "        pickle.dump(dataset, f)        \n",
        "\n",
        "def process_movielens1m_posters(directory, output_path, image_embeddings):\n",
        "\n",
        "    ## Build heterogeneous graph\n",
        "\n",
        "    # Load plot embeddings\n",
        "    embeddings = torch.load(image_embeddings, map_location='cpu')\n",
        "\n",
        "    # Load data\n",
        "    users = []\n",
        "    with open(os.path.join(directory, 'users.dat'), encoding='latin1') as f:\n",
        "        for l in f:\n",
        "            id_, gender, age, occupation, zip_ = l.strip().split('::')\n",
        "            users.append({\n",
        "                'user_id': int(id_),\n",
        "                'gender': gender,\n",
        "                'age': age,\n",
        "                'occupation': occupation,\n",
        "                'zip': zip_,\n",
        "                })\n",
        "    users = pd.DataFrame(users).astype('category')\n",
        "\n",
        "    movies = []\n",
        "    with open(os.path.join(directory, 'movies.dat'), encoding='latin1') as f:\n",
        "        for l in f:\n",
        "            id_, title, genres = l.strip().split('::')\n",
        "            genres_set = set(genres.split('|'))\n",
        "\n",
        "            # extract year\n",
        "            assert re.match(r'.*\\([0-9]{4}\\)$', title)\n",
        "            year = title[-5:-1]\n",
        "            title = title[:-6].strip()\n",
        "\n",
        "            data = {'movie_id': int(id_), 'title': title, 'year': year}\n",
        "            for g in genres_set:\n",
        "                data[g] = True\n",
        "            movies.append(data)\n",
        "    movies = pd.DataFrame(movies).astype({'year': 'category'})\n",
        "\n",
        "    ratings = []\n",
        "    with open(os.path.join(directory, 'ratings.dat'), encoding='latin1') as f:\n",
        "        for l in f:\n",
        "            user_id, movie_id, rating, timestamp = [int(_) for _ in l.split('::')]\n",
        "            ratings.append({\n",
        "                'user_id': user_id,\n",
        "                'movie_id': movie_id,\n",
        "                'rating': rating,\n",
        "                'timestamp': timestamp,\n",
        "                })\n",
        "    ratings = pd.DataFrame(ratings)\n",
        "\n",
        "    # Filter the users and items that never appear in the rating table.    \n",
        "    distinct_users_in_ratings = ratings['user_id'].unique()\n",
        "    distinct_movies_in_ratings = ratings['movie_id'].unique()\n",
        "    users = users[users['user_id'].isin(distinct_users_in_ratings)]\n",
        "    movies = movies[movies['movie_id'].isin(distinct_movies_in_ratings)]\n",
        "\n",
        "    # Filter users and items for movies that don't have embeddings\n",
        "    distinct_movies = movies['movie_id'].unique()\n",
        "\n",
        "    # drop embeddings for movies not in set\n",
        "    distinct_movies_with_embeddings = np.array(embeddings['ml_ids'])    \n",
        "    embedding_has_rating = np.in1d(distinct_movies_with_embeddings, distinct_movies)\n",
        "    distinct_movies_with_embeddings = distinct_movies_with_embeddings[embedding_has_rating]\n",
        "\n",
        "    # drop movies without embedding\n",
        "    movie_has_embedding = np.in1d(distinct_movies, distinct_movies_with_embeddings)\n",
        "    rated_movies_with_embeddings = distinct_movies[movie_has_embedding]\n",
        "\n",
        "    # Filter ratings, users, movies\n",
        "    ratings = ratings[ratings['movie_id'].isin(rated_movies_with_embeddings)]\n",
        "    distinct_users_in_ratings = ratings['user_id'].unique()\n",
        "    distinct_movies_in_ratings = ratings['movie_id'].unique()\n",
        "    #filtering users breaks everything, do don't\n",
        "    #users = users[users['user_id'].isin(distinct_users_in_ratings)]\n",
        "    movies = movies[movies['movie_id'].isin(distinct_movies_in_ratings)]        \n",
        "    print(f\"movies included: {len(movies)}\")\n",
        "\n",
        "    # align the plot data with the movies dataframe\n",
        "    # use_embeddings = np.in1d(np.array(embeddings['ml_ids']), movies['movie_id'].unique())\n",
        "    image_data = []\n",
        "    for r,movie in progress_bar(movies.iterrows(), total=len(movies)):\n",
        "      idx = embeddings['ml_ids'].index(movie.movie_id)\n",
        "      image_data.append(embeddings['embedding'][idx])\n",
        "\n",
        "    # Group the movie features into genres (a vector), year (a category), title (a string)\n",
        "    genre_columns = movies.columns.drop(['movie_id', 'title', 'year'])\n",
        "    movies[genre_columns] = movies[genre_columns].fillna(False).astype('bool')\n",
        "    movies_categorical = movies.drop('title', axis=1)    \n",
        "\n",
        "    # Build graph\n",
        "    graph_builder = PandasGraphBuilder()\n",
        "    graph_builder.add_entities(users, 'user_id', 'user')\n",
        "    graph_builder.add_entities(movies_categorical, 'movie_id', 'movie')\n",
        "    graph_builder.add_binary_relations(ratings, 'user_id', 'movie_id', 'watched')\n",
        "    graph_builder.add_binary_relations(ratings, 'movie_id', 'user_id', 'watched-by')\n",
        "\n",
        "    g = graph_builder.build()\n",
        "\n",
        "    # Assign features.\n",
        "    # Note that variable-sized features such as texts or images are handled elsewhere.\n",
        "    g.nodes['user'].data['gender'] = torch.LongTensor(users['gender'].cat.codes.values)\n",
        "    g.nodes['user'].data['age'] = torch.LongTensor(users['age'].cat.codes.values)\n",
        "    g.nodes['user'].data['occupation'] = torch.LongTensor(users['occupation'].cat.codes.values)\n",
        "    g.nodes['user'].data['zip'] = torch.LongTensor(users['zip'].cat.codes.values)\n",
        "\n",
        "    g.nodes['movie'].data['year'] = torch.LongTensor(movies['year'].cat.codes.values)\n",
        "    g.nodes['movie'].data['genre'] = torch.FloatTensor(movies[genre_columns].values)    \n",
        "    g.nodes['movie'].data['poster'] = torch.stack(image_data)\n",
        "    \n",
        "    g.edges['watched'].data['rating'] = torch.LongTensor(ratings['rating'].values)\n",
        "    g.edges['watched'].data['timestamp'] = torch.LongTensor(ratings['timestamp'].values)\n",
        "    g.edges['watched-by'].data['rating'] = torch.LongTensor(ratings['rating'].values)\n",
        "    g.edges['watched-by'].data['timestamp'] = torch.LongTensor(ratings['timestamp'].values)\n",
        "\n",
        "    # Train-validation-test split\n",
        "    # This is a little bit tricky as we want to select the last interaction for test, and the\n",
        "    # second-to-last interaction for validation.\n",
        "    train_indices, val_indices, test_indices = train_test_split_by_time(ratings, 'timestamp', 'user_id')\n",
        "\n",
        "    # Build the graph with training interactions only.\n",
        "    train_g = build_train_graph(g, train_indices, 'user', 'movie', 'watched', 'watched-by')\n",
        "    assert train_g.out_degrees(etype='watched').min() > 0\n",
        "\n",
        "    # Build the user-item sparse matrix for validation and test set.\n",
        "    val_matrix, test_matrix = build_val_test_matrix(g, val_indices, test_indices, 'user', 'movie', 'watched')\n",
        "\n",
        "    ## Build title set\n",
        "\n",
        "    movie_textual_dataset = {'title': movies['title'].values}\n",
        "\n",
        "    # The model should build their own vocabulary and process the texts.  Here is one example\n",
        "    # of using torchtext to pad and numericalize a batch of strings.\n",
        "    #     field = torchtext.data.Field(include_lengths=True, lower=True, batch_first=True)\n",
        "    #     examples = [torchtext.data.Example.fromlist([t], [('title', title_field)]) for t in texts]\n",
        "    #     titleset = torchtext.data.Dataset(examples, [('title', title_field)])\n",
        "    #     field.build_vocab(titleset.title, vectors='fasttext.simple.300d')\n",
        "    #     token_ids, lengths = field.process([examples[0].title, examples[1].title])\n",
        "\n",
        "    ## Dump the graph and the datasets\n",
        "\n",
        "    dataset = {\n",
        "        'train-graph': train_g,\n",
        "        'val-matrix': val_matrix,\n",
        "        'test-matrix': test_matrix,\n",
        "        'item-texts': movie_textual_dataset,\n",
        "        'item-images': None,\n",
        "        'user-type': 'user',\n",
        "        'item-type': 'movie',\n",
        "        'user-to-item-type': 'watched',\n",
        "        'item-to-user-type': 'watched-by',\n",
        "        'timestamp-edge-column': 'timestamp'}\n",
        "\n",
        "    with open(output_path, 'wb') as f:\n",
        "        pickle.dump(dataset, f)                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTpPoa1GL46H"
      },
      "source": [
        "process_movielens1m_text('/content/ml-1m', '/content/ml_1m_imdb_synopsis.pkl', \n",
        "                         'ml_25m_links_imdb_synopsis_paraphrase-distilroberta-base-v1.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZInmJtCL9-w"
      },
      "source": [
        "process_movielens1m_text('/content/ml-1m', '/content/ml_1m_imdb_plot.pkl', \n",
        "                         'ml_25m_links_imdb_plot_paraphrase-distilroberta-base-v1.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMMyptA-MAu7"
      },
      "source": [
        "process_movielens1m_text('/content/ml-1m', '/content/ml_1m_imdb_longest.pkl', \n",
        "                         'ml_25m_links_imdb_longest_paraphrase-distilroberta-base-v1.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6RkuO9vYAmd"
      },
      "source": [
        "process_movielens1m_text('/content/ml-1m', '/content/ml_1m_imdb_full_plot.pkl', \n",
        "                         'ml_25m_links_imdb_full_plot_paraphrase-distilroberta-base-v1.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_s9yoIQv6Gv"
      },
      "source": [
        "process_movielens1m_posters('/content/ml-1m', '/content/ml_1m_backdrop_vgg16.pkl', \n",
        "                            'tmdb_backdrops_w780_VGG_classifier.4.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3U-ISIY7hDJ"
      },
      "source": [
        "process_movielens1m_posters('/content/ml-1m', '/content/ml_1m_backdrop_swin.pkl', \n",
        "                            'tmdb_backdrops_w780_SwinTransformer_avgpool.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY67cbeJbz2-"
      },
      "source": [
        "process_movielens1m_text('/content/ml-1m', '/content/ml_1m_plot_data.pkl', \n",
        "                         'ml_25m_tmdb_plot_paraphrase-distilroberta-base-v1.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih9lEs2WBN86"
      },
      "source": [
        "process_movielens1m_text('/content/ml-1m', '/content/ml_1m_only_id.pkl', \n",
        "                         'ml_25m_links_imdb_longest_paraphrase-distilroberta-base-v1.pth.tar',\n",
        "                        only_id=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycVsgqyFL9s9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pHlevgQNa5r"
      },
      "source": [
        "# PinSage Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUgjyg8fODIe"
      },
      "source": [
        "## PinSage Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLs94jT5OABh"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl\n",
        "import dgl.nn.pytorch as dglnn\n",
        "import dgl.function as fn\n",
        "\n",
        "def disable_grad(module):\n",
        "    for param in module.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "def _init_input_modules(g, ntype, textset, hidden_dims):\n",
        "    # We initialize the linear projections of each input feature ``x`` as\n",
        "    # follows:\n",
        "    # * If ``x`` is a scalar integral feature, we assume that ``x`` is a categorical\n",
        "    #   feature, and assume the range of ``x`` is 0..max(x).\n",
        "    # * If ``x`` is a float one-dimensional feature, we assume that ``x`` is a\n",
        "    #   numeric vector.\n",
        "    # * If ``x`` is a field of a textset, we process it as bag of words.\n",
        "    module_dict = nn.ModuleDict()\n",
        "\n",
        "    for column, data in g.nodes[ntype].data.items():\n",
        "        if column == dgl.NID:\n",
        "            continue\n",
        "        if data.dtype == torch.float32:\n",
        "            assert data.ndim == 2\n",
        "            m = nn.Linear(data.shape[1], hidden_dims)\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            module_dict[column] = m\n",
        "        elif data.dtype == torch.int64:\n",
        "            assert data.ndim == 1\n",
        "            m = nn.Embedding(\n",
        "                data.max() + 2, hidden_dims, padding_idx=-1)\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "            module_dict[column] = m\n",
        "\n",
        "    if textset is not None:\n",
        "        for column, field in textset.fields.items():\n",
        "            if field.vocab.vectors:\n",
        "                module_dict[column] = BagOfWordsPretrained(field, hidden_dims)\n",
        "            else:\n",
        "                module_dict[column] = BagOfWords(field, hidden_dims)\n",
        "\n",
        "    return module_dict\n",
        "\n",
        "class BagOfWordsPretrained(nn.Module):\n",
        "    def __init__(self, field, hidden_dims):\n",
        "        super().__init__()\n",
        "\n",
        "        input_dims = field.vocab.vectors.shape[1]\n",
        "        self.emb = nn.Embedding(\n",
        "            len(field.vocab.itos), input_dims,\n",
        "            padding_idx=field.vocab.stoi[field.pad_token])\n",
        "        self.emb.weight[:] = field.vocab.vectors\n",
        "        self.proj = nn.Linear(input_dims, hidden_dims)\n",
        "        nn.init.xavier_uniform_(self.proj.weight)\n",
        "        nn.init.constant_(self.proj.bias, 0)\n",
        "\n",
        "        disable_grad(self.emb)\n",
        "\n",
        "    def forward(self, x, length):\n",
        "        \"\"\"\n",
        "        x: (batch_size, max_length) LongTensor\n",
        "        length: (batch_size,) LongTensor\n",
        "        \"\"\"\n",
        "        x = self.emb(x).sum(1) / length.unsqueeze(1).float()\n",
        "        return self.proj(x)\n",
        "\n",
        "class BagOfWords(nn.Module):\n",
        "    def __init__(self, field, hidden_dims):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb = nn.Embedding(\n",
        "            len(field.vocab.itos), hidden_dims,\n",
        "            padding_idx=field.vocab.stoi[field.pad_token])\n",
        "        nn.init.xavier_uniform_(self.emb.weight)\n",
        "\n",
        "    def forward(self, x, length):\n",
        "        return self.emb(x).sum(1) / length.unsqueeze(1).float()\n",
        "\n",
        "class LinearProjector(nn.Module):\n",
        "    \"\"\"\n",
        "    Projects each input feature of the graph linearly and sums them up\n",
        "    \"\"\"\n",
        "    def __init__(self, full_graph, ntype, textset, hidden_dims):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ntype = ntype\n",
        "        self.inputs = _init_input_modules(full_graph, ntype, textset, hidden_dims)\n",
        "\n",
        "    def forward(self, ndata):\n",
        "        projections = []\n",
        "        for feature, data in ndata.items():\n",
        "            if feature == dgl.NID or feature.endswith('__len'):\n",
        "                # This is an additional feature indicating the length of the ``feature``\n",
        "                # column; we shouldn't process this.\n",
        "                continue\n",
        "\n",
        "            module = self.inputs[feature]\n",
        "            if isinstance(module, (BagOfWords, BagOfWordsPretrained)):\n",
        "                # Textual feature; find the length and pass it to the textual module.\n",
        "                length = ndata[feature + '__len']\n",
        "                result = module(data, length)\n",
        "            else:\n",
        "                result = module(data)\n",
        "            projections.append(result)\n",
        "\n",
        "        return torch.stack(projections, 1).sum(1)\n",
        "\n",
        "class WeightedSAGEConv(nn.Module):\n",
        "    def __init__(self, input_dims, hidden_dims, output_dims, act=F.relu):\n",
        "        super().__init__()\n",
        "\n",
        "        self.act = act\n",
        "        self.Q = nn.Linear(input_dims, hidden_dims)\n",
        "        self.W = nn.Linear(input_dims + hidden_dims, output_dims)\n",
        "        self.reset_parameters()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        gain = nn.init.calculate_gain('relu')\n",
        "        nn.init.xavier_uniform_(self.Q.weight, gain=gain)\n",
        "        nn.init.xavier_uniform_(self.W.weight, gain=gain)\n",
        "        nn.init.constant_(self.Q.bias, 0)\n",
        "        nn.init.constant_(self.W.bias, 0)\n",
        "\n",
        "    def forward(self, g, h, weights):\n",
        "        \"\"\"\n",
        "        g : graph\n",
        "        h : node features\n",
        "        weights : scalar edge weights\n",
        "        \"\"\"\n",
        "        h_src, h_dst = h\n",
        "        with g.local_scope():\n",
        "            g.srcdata['n'] = self.act(self.Q(self.dropout(h_src)))\n",
        "            g.edata['w'] = weights.float()\n",
        "            g.update_all(fn.u_mul_e('n', 'w', 'm'), fn.sum('m', 'n'))\n",
        "            g.update_all(fn.copy_e('w', 'm'), fn.sum('m', 'ws'))\n",
        "            n = g.dstdata['n']\n",
        "            ws = g.dstdata['ws'].unsqueeze(1).clamp(min=1)\n",
        "            z = self.act(self.W(self.dropout(torch.cat([n / ws, h_dst], 1))))\n",
        "            z_norm = z.norm(2, 1, keepdim=True)\n",
        "            z_norm = torch.where(z_norm == 0, torch.tensor(1.).to(z_norm), z_norm)\n",
        "            z = z / z_norm\n",
        "            return z\n",
        "\n",
        "class SAGENet(nn.Module):\n",
        "    def __init__(self, hidden_dims, n_layers):\n",
        "        \"\"\"\n",
        "        g : DGLHeteroGraph\n",
        "            The user-item interaction graph.\n",
        "            This is only for finding the range of categorical variables.\n",
        "        item_textsets : torchtext.data.Dataset\n",
        "            The textual features of each item node.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(n_layers):\n",
        "            self.convs.append(WeightedSAGEConv(hidden_dims, hidden_dims, hidden_dims))\n",
        "\n",
        "    def forward(self, blocks, h):\n",
        "        for layer, block in zip(self.convs, blocks):\n",
        "            h_dst = h[:block.number_of_nodes('DST/' + block.ntypes[0])]\n",
        "            h = layer(block, (h, h_dst), block.edata['weights'])\n",
        "        return h\n",
        "\n",
        "class ItemToItemScorer(nn.Module):\n",
        "    def __init__(self, full_graph, ntype):\n",
        "        super().__init__()\n",
        "\n",
        "        n_nodes = full_graph.number_of_nodes(ntype)\n",
        "        self.bias = nn.Parameter(torch.zeros(n_nodes))\n",
        "\n",
        "    def _add_bias(self, edges):\n",
        "        bias_src = self.bias[edges.src[dgl.NID]]\n",
        "        bias_dst = self.bias[edges.dst[dgl.NID]]\n",
        "        return {'s': edges.data['s'] + bias_src + bias_dst}\n",
        "\n",
        "    def forward(self, item_item_graph, h):\n",
        "        \"\"\"\n",
        "        item_item_graph : graph consists of edges connecting the pairs\n",
        "        h : hidden state of every node\n",
        "        \"\"\"\n",
        "        with item_item_graph.local_scope():\n",
        "            item_item_graph.ndata['h'] = h\n",
        "            item_item_graph.apply_edges(fn.u_dot_v('h', 'h', 's'))\n",
        "            item_item_graph.apply_edges(self._add_bias)\n",
        "            pair_score = item_item_graph.edata['s']\n",
        "        return pair_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL-U9yVKOWRq"
      },
      "source": [
        "## PinSage Sampler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqCyiT8NOVeq"
      },
      "source": [
        "import numpy as np\n",
        "import dgl\n",
        "import torch\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "\n",
        "def compact_and_copy(frontier, seeds):\n",
        "    block = dgl.to_block(frontier, seeds)\n",
        "    for col, data in frontier.edata.items():\n",
        "        if col == dgl.EID:\n",
        "            continue\n",
        "        block.edata[col] = data[block.edata[dgl.EID]]\n",
        "    return block\n",
        "\n",
        "class ItemToItemBatchSampler(IterableDataset):\n",
        "    def __init__(self, g, user_type, item_type, batch_size):\n",
        "        self.g = g\n",
        "        self.user_type = user_type\n",
        "        self.item_type = item_type\n",
        "        self.user_to_item_etype = list(g.metagraph()[user_type][item_type])[0]\n",
        "        self.item_to_user_etype = list(g.metagraph()[item_type][user_type])[0]\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __iter__(self):\n",
        "        while True:\n",
        "            heads = torch.randint(0, self.g.number_of_nodes(self.item_type), (self.batch_size,))\n",
        "            tails = dgl.sampling.random_walk(\n",
        "                self.g,\n",
        "                heads,\n",
        "                metapath=[self.item_to_user_etype, self.user_to_item_etype])[0][:, 2]\n",
        "            neg_tails = torch.randint(0, self.g.number_of_nodes(self.item_type), (self.batch_size,))\n",
        "\n",
        "            mask = (tails != -1)\n",
        "            yield heads[mask], tails[mask], neg_tails[mask]\n",
        "\n",
        "class NeighborSampler(object):\n",
        "    def __init__(self, g, user_type, item_type, random_walk_length, random_walk_restart_prob,\n",
        "                 num_random_walks, num_neighbors, num_layers):\n",
        "        self.g = g\n",
        "        self.user_type = user_type\n",
        "        self.item_type = item_type\n",
        "        self.user_to_item_etype = list(g.metagraph()[user_type][item_type])[0]\n",
        "        self.item_to_user_etype = list(g.metagraph()[item_type][user_type])[0]\n",
        "        self.samplers = [\n",
        "            dgl.sampling.PinSAGESampler(g, item_type, user_type, random_walk_length,\n",
        "                random_walk_restart_prob, num_random_walks, num_neighbors)\n",
        "            for _ in range(num_layers)]\n",
        "\n",
        "    def sample_blocks(self, seeds, heads=None, tails=None, neg_tails=None):\n",
        "        blocks = []\n",
        "        for sampler in self.samplers:\n",
        "            frontier = sampler(seeds)\n",
        "            if heads is not None:\n",
        "                eids = frontier.edge_ids(torch.cat([heads, heads]), torch.cat([tails, neg_tails]), return_uv=True)[2]\n",
        "                if len(eids) > 0:\n",
        "                    old_frontier = frontier\n",
        "                    frontier = dgl.remove_edges(old_frontier, eids)\n",
        "                    #print(old_frontier)\n",
        "                    #print(frontier)\n",
        "                    #print(frontier.edata['weights'])\n",
        "                    #frontier.edata['weights'] = old_frontier.edata['weights'][frontier.edata[dgl.EID]]\n",
        "            block = compact_and_copy(frontier, seeds)\n",
        "            seeds = block.srcdata[dgl.NID]\n",
        "            blocks.insert(0, block)\n",
        "        return blocks\n",
        "\n",
        "    def sample_from_item_pairs(self, heads, tails, neg_tails):\n",
        "        # Create a graph with positive connections only and another graph with negative\n",
        "        # connections only.\n",
        "        pos_graph = dgl.graph(\n",
        "            (heads, tails),\n",
        "            num_nodes=self.g.number_of_nodes(self.item_type))\n",
        "        neg_graph = dgl.graph(\n",
        "            (heads, neg_tails),\n",
        "            num_nodes=self.g.number_of_nodes(self.item_type))\n",
        "        pos_graph, neg_graph = dgl.compact_graphs([pos_graph, neg_graph])\n",
        "        seeds = pos_graph.ndata[dgl.NID]\n",
        "\n",
        "        blocks = self.sample_blocks(seeds, heads, tails, neg_tails)\n",
        "        return pos_graph, neg_graph, blocks\n",
        "\n",
        "def assign_simple_node_features(ndata, g, ntype, assign_id=False):\n",
        "    \"\"\"\n",
        "    Copies data to the given block from the corresponding nodes in the original graph.\n",
        "    \"\"\"\n",
        "    for col in g.nodes[ntype].data.keys():\n",
        "        if not assign_id and col == dgl.NID:\n",
        "            continue\n",
        "        induced_nodes = ndata[dgl.NID]\n",
        "        ndata[col] = g.nodes[ntype].data[col][induced_nodes]\n",
        "\n",
        "def assign_textual_node_features(ndata, textset, ntype):\n",
        "    \"\"\"\n",
        "    Assigns numericalized tokens from a torchtext dataset to given block.\n",
        "    The numericalized tokens would be stored in the block as node features\n",
        "    with the same name as ``field_name``.\n",
        "    The length would be stored as another node feature with name\n",
        "    ``field_name + '__len'``.\n",
        "    block : DGLHeteroGraph\n",
        "        First element of the compacted blocks, with \"dgl.NID\" as the\n",
        "        corresponding node ID in the original graph, hence the index to the\n",
        "        text dataset.\n",
        "        The numericalized tokens (and lengths if available) would be stored\n",
        "        onto the blocks as new node features.\n",
        "    textset : torchtext.data.Dataset\n",
        "        A torchtext dataset whose number of examples is the same as that\n",
        "        of nodes in the original graph.\n",
        "    \"\"\"\n",
        "    node_ids = ndata[dgl.NID].numpy()\n",
        "\n",
        "    if textset is not None:\n",
        "      for field_name, field in textset.fields.items():\n",
        "          examples = [getattr(textset[i], field_name) for i in node_ids]\n",
        "\n",
        "          tokens, lengths = field.process(examples)\n",
        "\n",
        "          if not field.batch_first:\n",
        "              tokens = tokens.t()\n",
        "\n",
        "          ndata[field_name] = tokens\n",
        "          ndata[field_name + '__len'] = lengths\n",
        "\n",
        "def assign_features_to_blocks(blocks, g, textset, ntype):\n",
        "    # For the first block (which is closest to the input), copy the features from\n",
        "    # the original graph as well as the texts.\n",
        "    assign_simple_node_features(blocks[0].srcdata, g, ntype)\n",
        "    assign_textual_node_features(blocks[0].srcdata, textset, ntype)\n",
        "    assign_simple_node_features(blocks[-1].dstdata, g, ntype)\n",
        "    assign_textual_node_features(blocks[-1].dstdata, textset, ntype)\n",
        "\n",
        "class PinSAGECollator(object):\n",
        "    def __init__(self, sampler, g, ntype, textset):\n",
        "        self.sampler = sampler\n",
        "        self.ntype = ntype\n",
        "        self.g = g\n",
        "        self.textset = textset\n",
        "\n",
        "    def collate_train(self, batches):\n",
        "        heads, tails, neg_tails = batches[0]\n",
        "        # Construct multilayer neighborhood via PinSAGE...\n",
        "        pos_graph, neg_graph, blocks = self.sampler.sample_from_item_pairs(heads, tails, neg_tails)\n",
        "        assign_features_to_blocks(blocks, self.g, self.textset, self.ntype)\n",
        "\n",
        "        return pos_graph, neg_graph, blocks\n",
        "\n",
        "    def collate_test(self, samples):\n",
        "        batch = torch.LongTensor(samples)\n",
        "        blocks = self.sampler.sample_blocks(batch)\n",
        "        assign_features_to_blocks(blocks, self.g, self.textset, self.ntype)\n",
        "        return blocks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJCRXSOFOuMg"
      },
      "source": [
        "## PinSage Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh7N_wmlOwC7"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import pickle\n",
        "import dgl\n",
        "import argparse\n",
        "\n",
        "def prec(recommendations, ground_truth):\n",
        "    n_users, n_items = ground_truth.shape\n",
        "    K = recommendations.shape[1]\n",
        "    user_idx = np.repeat(np.arange(n_users), K)\n",
        "    item_idx = recommendations.flatten()\n",
        "    relevance = ground_truth[user_idx, item_idx].reshape((n_users, K))\n",
        "    hit = relevance.any(axis=1).mean()\n",
        "    return hit\n",
        "\n",
        "class LatestNNRecommender(object):\n",
        "    def __init__(self, user_ntype, item_ntype, user_to_item_etype, timestamp, batch_size):\n",
        "        self.user_ntype = user_ntype\n",
        "        self.item_ntype = item_ntype\n",
        "        self.user_to_item_etype = user_to_item_etype\n",
        "        self.batch_size = batch_size\n",
        "        self.timestamp = timestamp\n",
        "\n",
        "    def recommend(self, full_graph, K, h_user, h_item):\n",
        "        \"\"\"\n",
        "        Return a (n_user, K) matrix of recommended items for each user\n",
        "        \"\"\"\n",
        "        graph_slice = full_graph.edge_type_subgraph([self.user_to_item_etype])\n",
        "        n_users = full_graph.number_of_nodes(self.user_ntype)\n",
        "        latest_interactions = dgl.sampling.select_topk(graph_slice, 1, self.timestamp, edge_dir='out')\n",
        "        user, latest_items = latest_interactions.all_edges(form='uv', order='srcdst')\n",
        "        # each user should have at least one \"latest\" interaction\n",
        "        assert torch.equal(user, torch.arange(n_users))\n",
        "\n",
        "        recommended_batches = []\n",
        "        user_batches = torch.arange(n_users).split(self.batch_size)\n",
        "        for user_batch in user_batches:\n",
        "            latest_item_batch = latest_items[user_batch].to(device=h_item.device)\n",
        "            dist = h_item[latest_item_batch] @ h_item.t()\n",
        "            # exclude items that are already interacted\n",
        "            for i, u in enumerate(user_batch.tolist()):\n",
        "                interacted_items = full_graph.successors(u, etype=self.user_to_item_etype)\n",
        "                dist[i, interacted_items] = -np.inf\n",
        "            recommended_batches.append(dist.topk(K, 1)[1])\n",
        "\n",
        "        recommendations = torch.cat(recommended_batches, 0)\n",
        "        return recommendations\n",
        "\n",
        "\n",
        "def evaluate_nn(dataset, h_item, k, batch_size):\n",
        "    g = dataset['train-graph']\n",
        "    val_matrix = dataset['val-matrix'].tocsr()\n",
        "    test_matrix = dataset['test-matrix'].tocsr()\n",
        "    item_texts = dataset['item-texts']\n",
        "    user_ntype = dataset['user-type']\n",
        "    item_ntype = dataset['item-type']\n",
        "    user_to_item_etype = dataset['user-to-item-type']\n",
        "    timestamp = dataset['timestamp-edge-column']\n",
        "\n",
        "    rec_engine = LatestNNRecommender(\n",
        "        user_ntype, item_ntype, user_to_item_etype, timestamp, batch_size)\n",
        "\n",
        "    recommendations = rec_engine.recommend(g, k, None, h_item).cpu().numpy()\n",
        "    return prec(recommendations, val_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ88V0E6OzT1"
      },
      "source": [
        "## PinSage Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvm6PajfNaLB"
      },
      "source": [
        "import pickle\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchtext\n",
        "import dgl\n",
        "import tqdm\n",
        "\n",
        "import madgrad \n",
        "from fastprogress.fastprogress import master_bar, progress_bar \n",
        "\n",
        "# import layers\n",
        "# import sampler as sampler_module\n",
        "# import evaluation\n",
        "\n",
        "class PinSAGEModel(nn.Module):\n",
        "    def __init__(self, full_graph, ntype, textsets, hidden_dims, n_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        self.proj = LinearProjector(full_graph, ntype, textsets, hidden_dims)\n",
        "        self.sage = SAGENet(hidden_dims, n_layers)\n",
        "        self.scorer = ItemToItemScorer(full_graph, ntype)\n",
        "\n",
        "    def forward(self, pos_graph, neg_graph, blocks):\n",
        "        h_item = self.get_repr(blocks)\n",
        "        pos_score = self.scorer(pos_graph, h_item)\n",
        "        neg_score = self.scorer(neg_graph, h_item)\n",
        "        return (neg_score - pos_score + 1).clamp(min=0)\n",
        "\n",
        "    def get_repr(self, blocks):\n",
        "        h_item = self.proj(blocks[0].srcdata)\n",
        "        h_item_dst = self.proj(blocks[-1].dstdata)\n",
        "        return h_item_dst + self.sage(blocks, h_item)\n",
        "\n",
        "def train_pinsage_implicit(args):\n",
        "    # Load dataset\n",
        "    with open(args.dataset_path, 'rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "    \n",
        "    g = dataset['train-graph']    \n",
        "    val_matrix = dataset['val-matrix'].tocsr()\n",
        "    test_matrix = dataset['test-matrix'].tocsr()\n",
        "    item_texts = dataset['item-texts']\n",
        "    user_ntype = dataset['user-type']\n",
        "    item_ntype = dataset['item-type']\n",
        "    user_to_item_etype = dataset['user-to-item-type']\n",
        "    timestamp = dataset['timestamp-edge-column']\n",
        "\n",
        "    device = torch.device(args.device)\n",
        "\n",
        "    # Assign user and movie IDs and use them as features (to learn an individual \n",
        "    # trainable embedding for each entity)\n",
        "    g.nodes[user_ntype].data['id'] = torch.arange(g.number_of_nodes(user_ntype))\n",
        "    g.nodes[item_ntype].data['id'] = torch.arange(g.number_of_nodes(item_ntype))\n",
        "\n",
        "    # Prepare torchtext dataset and vocabulary\n",
        "    if args.add_title:\n",
        "      fields = {}\n",
        "      examples = []\n",
        "      for key, texts in item_texts.items():\n",
        "          fields[key] = torchtext.legacy.data.Field(include_lengths=True, lower=True, batch_first=True)\n",
        "      for i in range(g.number_of_nodes(item_ntype)):\n",
        "          example = torchtext.legacy.data.Example.fromlist(\n",
        "              [item_texts[key][i] for key in item_texts.keys()],\n",
        "              [(key, fields[key]) for key in item_texts.keys()])\n",
        "          examples.append(example)\n",
        "      textset = torchtext.legacy.data.Dataset(examples, fields)\n",
        "      for key, field in fields.items():\n",
        "          field.build_vocab(getattr(textset, key))\n",
        "          #field.build_vocab(getattr(textset, key), vectors='fasttext.simple.300d')\n",
        "    else:\n",
        "      textset = None\n",
        "\n",
        "    # Sampler\n",
        "    batch_sampler = ItemToItemBatchSampler(\n",
        "        g, user_ntype, item_ntype, args.batch_size)\n",
        "    neighbor_sampler = NeighborSampler(\n",
        "        g, user_ntype, item_ntype, args.random_walk_length,\n",
        "        args.random_walk_restart_prob, args.num_random_walks, args.num_neighbors,\n",
        "        args.num_layers)\n",
        "    collator = PinSAGECollator(neighbor_sampler, g, item_ntype, textset)\n",
        "    dataloader = DataLoader(\n",
        "        batch_sampler,\n",
        "        collate_fn=collator.collate_train,\n",
        "        num_workers=args.num_workers)\n",
        "    dataloader_test = DataLoader(\n",
        "        torch.arange(g.number_of_nodes(item_ntype)),\n",
        "        batch_size=args.batch_size,\n",
        "        collate_fn=collator.collate_test,\n",
        "        num_workers=args.num_workers)\n",
        "    dataloader_it = iter(dataloader)\n",
        "\n",
        "    # Model\n",
        "    model = PinSAGEModel(g, item_ntype, textset, args.hidden_dims, args.num_layers).to(device)\n",
        "    print(model)\n",
        "\n",
        "    # Optimizer\n",
        "    if args.opt == 'MADGRAD':\n",
        "      opt = madgrad.MADGRAD(model.parameters(), lr=args.lr)\n",
        "    else:\n",
        "      opt = torch.optim.__dict__[args.opt](model.parameters(), lr=args.lr)\n",
        "    print(opt)\n",
        "\n",
        "    # For each batch of head-tail-negative triplets...\n",
        "    mb = master_bar(range(args.num_epochs))\n",
        "    for epoch_id in mb:\n",
        "        model.train()\n",
        "        for batch_id in progress_bar(range(args.batches_per_epoch), parent=mb):\n",
        "            pos_graph, neg_graph, blocks = next(dataloader_it)\n",
        "            # Copy to GPU\n",
        "            for i in range(len(blocks)):\n",
        "                blocks[i] = blocks[i].to(device, non_blocking=True)\n",
        "            pos_graph = pos_graph.to(device, non_blocking=True)\n",
        "            neg_graph = neg_graph.to(device, non_blocking=True)\n",
        "\n",
        "            loss = model(pos_graph, neg_graph, blocks).mean()\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        # Evaluate\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            item_batches = torch.arange(g.number_of_nodes(item_ntype)).split(args.batch_size)\n",
        "            h_item_batches = []\n",
        "            for blocks in dataloader_test:\n",
        "                for i in range(len(blocks)):\n",
        "                    blocks[i] = blocks[i].to(device)\n",
        "\n",
        "                h_item_batches.append(model.get_repr(blocks))\n",
        "            h_item = torch.cat(h_item_batches, 0)\n",
        "\n",
        "            hit_rate = evaluate_nn(dataset, h_item, args.k, args.batch_size)\n",
        "\n",
        "            print(f\"\\nEpoch [{epoch_id:02d}]/[{args.num_epochs:02d}]: Hit@{args.k}: {hit_rate:2.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub7WNCUSKS3q"
      },
      "source": [
        "# Check model with data\n",
        "\n",
        "Choose different datasets to see how the model automatically adjusts to fit the data in the graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS0550BQKVQC"
      },
      "source": [
        "import torch\n",
        "from types import SimpleNamespace\n",
        "\n",
        "args = SimpleNamespace()\n",
        "# args.dataset_path = '/content/data.pkl'\n",
        "# args.dataset_path = '/content/ml_1m_plot_data.pkl'\n",
        "# args.dataset_path = '/content/ml_1m_backdrop_swin.pkl'\n",
        "# args.dataset_path = '/content/ml_1m_imdb_longest.pkl'\n",
        "args.dataset_path = '/content/ml_1m_only_id.pkl'\n",
        "args.random_walk_length = 2\n",
        "args.random_walk_restart_prob = .5 \n",
        "args.num_random_walks = 1 \n",
        "args.num_neighbors = 3 \n",
        "args.num_layers = 2 \n",
        "args.hidden_dims = 16\n",
        "args.batch_size = 32 \n",
        "args.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "args.num_epochs = 10\n",
        "args.batches_per_epoch = 20000\n",
        "args.num_workers = 2\n",
        "args.lr = 3e-5\n",
        "args.k = 10\n",
        "args.opt = 'MADGRAD' # Adam, AdamW, MADGRAD\n",
        "args.add_title = False\n",
        "print(args)\n",
        "\n",
        "# Load dataset\n",
        "with open(args.dataset_path, 'rb') as f:\n",
        "    dataset = pickle.load(f)\n",
        "\n",
        "g = dataset['train-graph']\n",
        "val_matrix = dataset['val-matrix'].tocsr()\n",
        "test_matrix = dataset['test-matrix'].tocsr()\n",
        "item_texts = dataset['item-texts']\n",
        "user_ntype = dataset['user-type']\n",
        "item_ntype = dataset['item-type']\n",
        "user_to_item_etype = dataset['user-to-item-type']\n",
        "timestamp = dataset['timestamp-edge-column']\n",
        "\n",
        "device = torch.device(args.device)\n",
        "\n",
        "# Assign user and movie IDs and use them as features (to learn an individual \n",
        "# trainable embedding for each entity)\n",
        "g.nodes[user_ntype].data['id'] = torch.arange(g.number_of_nodes(user_ntype))\n",
        "g.nodes[item_ntype].data['id'] = torch.arange(g.number_of_nodes(item_ntype))\n",
        "\n",
        "# drop features\n",
        "# del g.nodes['movie'].data['year']\n",
        "# del g.nodes['movie'].data['genre']\n",
        "# del g.nodes['movie'].data['plot']\n",
        "\n",
        "# Prepare torchtext dataset and vocabulary\n",
        "if args.add_title:\n",
        "  fields = {}\n",
        "  examples = []\n",
        "  for key, texts in item_texts.items():\n",
        "      fields[key] = torchtext.legacy.data.Field(include_lengths=True, lower=True, batch_first=True)\n",
        "  for i in range(g.number_of_nodes(item_ntype)):\n",
        "      example = torchtext.legacy.data.Example.fromlist(\n",
        "          [item_texts[key][i] for key in item_texts.keys()],\n",
        "          [(key, fields[key]) for key in item_texts.keys()])\n",
        "      examples.append(example)\n",
        "  textset = torchtext.legacy.data.Dataset(examples, fields)\n",
        "  for key, field in fields.items():\n",
        "      field.build_vocab(getattr(textset, key))\n",
        "      #field.build_vocab(getattr(textset, key), vectors='fasttext.simple.300d')\n",
        "else:\n",
        "  textset = None \n",
        "\n",
        "# Model\n",
        "model = PinSAGEModel(g, item_ntype, textset, args.hidden_dims, args.num_layers).to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK4A9b0iR-Y3"
      },
      "source": [
        "# PinSage Train on Implicit Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcaEj78dClg4"
      },
      "source": [
        "## template, don't use/edit this one, it's just for reference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5V-zscsCpug"
      },
      "source": [
        "from types import SimpleNamespace\n",
        "\n",
        "args = SimpleNamespace()\n",
        "args.dataset_path = '/content/data.pkl'\n",
        "# args.dataset_path = '/content/ml_1m_only_id.pkl'\n",
        "args.random_walk_length = 2\n",
        "args.random_walk_restart_prob = .5 \n",
        "args.num_random_walks = 1 \n",
        "args.num_neighbors = 3 \n",
        "args.num_layers = 2 \n",
        "args.hidden_dims = 16\n",
        "args.batch_size = 32 \n",
        "args.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "args.num_epochs = 10\n",
        "args.batches_per_epoch = 20000\n",
        "args.num_workers = 2\n",
        "args.lr = 3e-5\n",
        "args.k = 10\n",
        "args.opt = 'MADGRAD' # Adam, AdamW, MADGRAD\n",
        "args.add_title = True \n",
        "print(args)\n",
        "\n",
        "# baseline (movie id only): Epoch [09]/[10]: Hit@10: 0.042\n",
        "# all movie data plus longest plot: Epoch [09]/[10]: Hit@10: 0.080\n",
        "# without plot (MADGRAD): Epoch [09]/[10]: Hit@10: 0.081\n",
        "# with plot (MADGRAD): Epoch [09]/[10]: Hit@10: 0.060\n",
        "# with plot (ADAMW): Epoch [09]/[10]: Hit@10: 0.064\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG8ufOynCZAL"
      },
      "source": [
        "## baseline model, movie id only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKOIOwtECfd3"
      },
      "source": [
        "from types import SimpleNamespace\n",
        "\n",
        "args = SimpleNamespace()\n",
        "args.dataset_path = '/content/ml_1m_only_id.pkl'\n",
        "args.random_walk_length = 2\n",
        "args.random_walk_restart_prob = .5 \n",
        "args.num_random_walks = 1 \n",
        "args.num_neighbors = 3 \n",
        "args.num_layers = 2 \n",
        "args.hidden_dims = 32 # 16\n",
        "args.batch_size = 256 # 32\n",
        "args.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "args.num_epochs = 10\n",
        "args.batches_per_epoch = 20000\n",
        "args.num_workers = 4\n",
        "args.lr = 3e-5\n",
        "args.k = 10\n",
        "args.opt = 'MADGRAD' # Adam, AdamW, MADGRAD\n",
        "args.add_title = False \n",
        "\n",
        "print(args)\n",
        "train_pinsage_implicit(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViU4_LzIuZ2A"
      },
      "source": [
        "# possible variations\n",
        "\n",
        "You can try different datasets (i.e., change the name of the data file being used to load the graph - the PinSage model automatically adapts to the data in the Graph):\n",
        "- [ ] ml_1m_only_id.pkl (this is our baseline)\n",
        "- [ ] ml_1m_imdb_plot.pkl(embedding of short plot descriptions)\n",
        "- [ ] ml_1m_imdb_full_plot.pkl (embedding of long plot descriptions)\n",
        "- [ ] ml_1m_imdb_synopsis.pkl (embedding of pages-long movie summaries)\n",
        "- [ ] ml_1m_imdb_longest.pkl (embedding of longest-available text, since many movies don't have a full synposis, we fall back to the full plot or short plot as needed)\n",
        "- [ ] ml_1m_poster_swin (movie poster embedding)\n",
        "- [ ] ml_1m_backdrop_swin (widescreen movie poster embedding)\n",
        "\n",
        "\n",
        "Or you can try different hyperparameters:\n",
        "- [ ] args.hidden_dims (number of dimensions used to encode node information)\n",
        "- [ ] args.num_layers (how many \"hops\" the PinSage random walk goes when building graphs)\n",
        "- [ ] args.num_random_walks (how many walks to take)\n",
        "- [ ] args.num_neighbors (how many neighbors to keep)\n",
        "\n",
        "You can make changes in the cell below and then run it to try a new model. If you run multiple variations, then just copy this code into a new cell for each variant, so you can use the cell output as a record."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8v4N4f4uWwS"
      },
      "source": [
        "from types import SimpleNamespace\n",
        "\n",
        "# Edit the Dataset path\n",
        "args = SimpleNamespace()\n",
        "args.dataset_path = '/content/ml_1m_only_id.pkl'\n",
        "args.random_walk_length = 2\n",
        "args.random_walk_restart_prob = .5 \n",
        "args.num_random_walks = 1 \n",
        "args.num_neighbors = 3 \n",
        "args.num_layers = 2 \n",
        "args.hidden_dims = 32 # 16\n",
        "args.batch_size = 256 # 32\n",
        "args.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "args.num_epochs = 10\n",
        "args.batches_per_epoch = 20000\n",
        "args.num_workers = 2\n",
        "args.lr = 3e-5\n",
        "args.k = 10\n",
        "args.opt = 'MADGRAD' # Adam, AdamW, MADGRAD\n",
        "args.add_title = False \n",
        "\n",
        "print(args)\n",
        "train_pinsage_implicit(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__mjdPRAM4wd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIZt5sxKNB1R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wskjzTovL0pU"
      },
      "source": [
        "# Summary & Conclusions\n",
        "Breifly write up a summary of what you did, what you found, and what you think it means.\n",
        "\n",
        "Then share this notebook (you're edited copy) with me (grez72@gmail.com) to submit your final project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk6e4aCLL3vL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}