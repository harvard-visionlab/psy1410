{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "psy1410_week02_anns.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM3FRvtaALElY+6sw7a7jli",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harvard-visionlab/psy1410/blob/master/psy1410_week02_anns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G8dsXxHdNo2"
      },
      "source": [
        "# Psy1410 - Week02 - Artificial Neural Networks with PyTorch\n",
        "\n",
        "This week we're going to use PyTorch to create and train ANNs on the MNIST digit recognition task.\n",
        "\n",
        "For this workshop, set your Runtime to GPU!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RefXEqWV6ryA"
      },
      "source": [
        "#required\n",
        "import torch \n",
        "\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM_hoFmZeVXx"
      },
      "source": [
        "## Import and define Helper Functions\n",
        "\n",
        "Here we'll define any helper functions that we can use as we go. We'll probably add to this as we find a need for new helper functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUoTnJyslo4V"
      },
      "source": [
        "#required\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPfYSf69eUVp"
      },
      "source": [
        "#required\n",
        "import numpy as np \n",
        "from PIL import Image \n",
        "from IPython.core.debugger import set_trace \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_image(img):\n",
        "  return Image.fromarray( (img * 256).squeeze().numpy().astype(np.uint8) )\n",
        "\n",
        "def show_weights(m):\n",
        "  idx = -1\n",
        "  fig, axs = plt.subplots(2, 5, figsize=(15, 6))\n",
        "  for row in axs:\n",
        "    for ax in row:\n",
        "      idx += 1\n",
        "      if hasattr(m, 'weight') and len(m.weight.shape) == 4:\n",
        "        shape = m.weight[idx].shape[1:]\n",
        "        w = m.weight[idx].detach().reshape(*shape).cpu()\n",
        "        ax.imshow(w, extent=[0, 1, 0, 1], cmap='gray')\n",
        "      elif hasattr(m, 'weight'):\n",
        "        w = m.weight[idx].detach().reshape(28,28).cpu()\n",
        "        ax.imshow(w, extent=[0, 1, 0, 1], cmap='coolwarm')\n",
        "      else:\n",
        "        w = m.fc.weight[idx].detach().reshape(28,28).cpu()\n",
        "        ax.imshow(w, extent=[0, 1, 0, 1], cmap='coolwarm')\n",
        "      ax.set_title(f\"unit={idx}\")\n",
        "      ax.grid(True)\n",
        "      ax.axes.get_xaxis().set_visible(False)\n",
        "      ax.axes.get_yaxis().set_visible(False)\n",
        "  plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUECmnLaa0HS"
      },
      "source": [
        "## A Minimal ANN\n",
        "\n",
        "Let's start by defining a very minimal artificial neural network, with a single fully-connected linear layer that directly maps the input (1x28x28 pixels) to the output categories (10 digit categories)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWf6zhV0aVhh"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyNet, self).__init__()\n",
        "    # in_features = 784, because the input image is 1x28x28 = 784\n",
        "    # out_features = 10, because there are 10 output categories (digits 0-9)\n",
        "    self.fc = nn.Linear(in_features=784, out_features=10)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # in the \"forward pass\", we take an input (a batch of images, x)\n",
        "    # then first we flatten it into batchSize x 784, \n",
        "    batchSize = x.shape[0] # first dimension of x is \"batchSize\"\n",
        "    x = x.view(batchSize, -1) # the -1 tells pytorch to flatten the tensor to be batchSize x \"whatever size fits\"\n",
        "\n",
        "    # finally, we pass the flattened input into our fully-connected layer \n",
        "    # which will compute the weighted sum of the input for each of the 10 \n",
        "    # categories\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVF5WTYma8kZ"
      },
      "source": [
        "# create an instance of MyNet\n",
        "model = MyNet()\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV5uyUnygtmy"
      },
      "source": [
        "# test on random data (100 random images)\n",
        "fake_imgs = torch.rand(100,1,28,28)\n",
        "out = model(fake_imgs)\n",
        "out.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5fS7spwhCAH"
      },
      "source": [
        "# why is the output shape \"100x10\"?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQSyqIE9jITL"
      },
      "source": [
        "# inspect the \"learnable parameters\" of your network\n",
        "# You should find 2 sets of parameters: 10 x 784 weights, and 10 biases\n",
        "params = list(model.parameters())\n",
        "print(len(params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiyWWCRijxAm"
      },
      "source": [
        "for param in params:\n",
        "  print(param.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2_dgHWIhfcj"
      },
      "source": [
        "## Inspect/visualize the weights of your randomly intialized network\n",
        "\n",
        "Remember that each output node has a weight on each of the 28x28 pixels. We can visualize these weights by color-coding the pixels according to the weight (negatives in blue, positives in red; brighter colors for larger weights)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wU3Lt7Vhboa"
      },
      "source": [
        "# we can directly access modules of the model, and their params, like so:\n",
        "model.fc.weight.shape, model.fc.bias.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqkdbYJ_h7l6"
      },
      "source": [
        "# grab the weights for the `zero` output node\n",
        "w = model.fc.weight[0].detach().reshape(28,28)\n",
        "w.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JbQ1tvoihQ3"
      },
      "source": [
        "plt.imshow(w, extent=[0, 1, 0, 1], cmap='coolwarm');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0Jp6ZCimJ55"
      },
      "source": [
        "show_weights(model.fc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQPzpWLxnmWo"
      },
      "source": [
        "## Let's Train this Model!\n",
        "\n",
        "We'll need:\n",
        "- [x] a model\n",
        "- [ ] a dataset (MNIST), with train/test split\n",
        "- [ ] a loss function (Cross Entropy Loss)\n",
        "- [ ] an optimizer (which will do all of the `back-propogation of errors` that we need to modify the weights\n",
        "- [ ] we need a training function\n",
        "- [ ] useful to have a validation function too (to test how well the model generalizes to data outside of the training set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z78ZTwlUbv1b"
      },
      "source": [
        "## MNIST Dataset\n",
        "\n",
        "- we'll start with the standard MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O9s7ZyubibD"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtQBx0wob0fg"
      },
      "source": [
        "train_dataset = datasets.MNIST('./data/MNIST', train=True, download=True, transform=transform)\n",
        "train_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTE-g9lJb1jn"
      },
      "source": [
        "test_dataset = datasets.MNIST('./data/MNIST', train=False, download=True, transform=transform)\n",
        "test_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qd7kL6yncInv"
      },
      "source": [
        "train_dataset[0][0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4-hNP8EcPG3"
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiVthmtOcyCh"
      },
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=256, \n",
        "                          num_workers=4, pin_memory=True, shuffle=True)\n",
        "train_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0WMRT_NdBrU"
      },
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=256, \n",
        "                         num_workers=4, pin_memory=True, shuffle=False)\n",
        "test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYYQxFSZdLz_"
      },
      "source": [
        "imgs, labels = next(iter(train_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn7DjCJpdRI0"
      },
      "source": [
        "imgs.shape, labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjXEi1rQdRxI"
      },
      "source": [
        "output = model(imgs)\n",
        "output.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qiQRCx9drE7"
      },
      "source": [
        "idx = 10\n",
        "actual = labels[idx].item()\n",
        "print(actual)\n",
        "show_image(imgs[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nE8EBtOd41P"
      },
      "source": [
        "softmax = output[idx].exp()/output[idx].exp().sum()\n",
        "softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3Jax1gkera-"
      },
      "source": [
        "predicted = softmax.argmax().item() \n",
        "print(f\"predicted={predicted}, actual={actual}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nzM4CmeohBq"
      },
      "source": [
        "## Loss Function\n",
        "\n",
        "Let's use the standard cross-entropy loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMlI_11le-Fg"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wui1FcHLpVzh"
      },
      "source": [
        "# create a fresh instance of your model \n",
        "model = MyNet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClfvAHk1op_N"
      },
      "source": [
        "# define loss function (criterion)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gjo59-9bpO3X"
      },
      "source": [
        "# pass some images through your model, get the outputs\n",
        "# why is the output 256 x 10?\n",
        "imgs, labels = next(iter(train_loader))\n",
        "output = model(imgs)\n",
        "output.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhqoM-EJpbVo"
      },
      "source": [
        "loss = criterion(output, labels)\n",
        "loss "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rALwxLI5pk2u"
      },
      "source": [
        "## Define the Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUtgJHR6pC3X"
      },
      "source": [
        "# define the optimizer\n",
        "# this updates the weights for us using gradient descent\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=.03)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40uAyAqNpwNn"
      },
      "source": [
        "## The training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgTfJ9gCqbRn"
      },
      "source": [
        "#required\n",
        "def train(model, train_loader, criterion, optimizer, mb=None):\n",
        "  # use gpu if available\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'  \n",
        "  model.to(device)\n",
        "  criterion.to(device)\n",
        "\n",
        "  # place model in \"train mode\" so gradients are computed\n",
        "  model.train()\n",
        "  \n",
        "  # loop through ALL images\n",
        "  losses = []\n",
        "  for imgs,labels in progress_bar(train_loader, parent=mb):\n",
        "    # put images and labels on gpu if available\n",
        "    imgs = imgs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # forward pass (pass images through model)\n",
        "    output = model(imgs)\n",
        "\n",
        "    # compute the loss \n",
        "    loss = criterion(output, labels)\n",
        "\n",
        "    # backward pass (compute gradients, do backprop)\n",
        "    optimizer.zero_grad() # zero out any existing gradients\n",
        "    loss.backward()       # compute gradients (tells us which direction to change weights)\n",
        "    optimizer.step()      # modify learnable parameters (optimizer decides how much to update weights, in direction of gradients)\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "  return torch.tensor(losses).mean().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccuTg-tI5Tx6"
      },
      "source": [
        "## The \"test\" or \"validation\" loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tsz2THf5SXL"
      },
      "source": [
        "#required\n",
        "def validate(model, test_loader, criterion, optimizer, mb=None):\n",
        "  # use gpu if available\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  model.to(device)\n",
        "  criterion.to(device)\n",
        "\n",
        "  # place the model in \"eval\" mode (do not compute gradients during testing) \n",
        "  model.eval()  \n",
        "\n",
        "  # iterate over batches, compute loss and accuracy for each batch\n",
        "  losses = []\n",
        "  correct = []\n",
        "  for imgs,labels in progress_bar(test_loader, parent=mb):\n",
        "    imgs = imgs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # forward pass \n",
        "    output = model(imgs)\n",
        "\n",
        "    # calculate loss and classification accuracy\n",
        "    loss = criterion(output, labels)\n",
        "    _, correct_k = accuracy(output, labels, topk=(1,))             \n",
        "\n",
        "    losses.append(loss.item())\n",
        "    correct.append(correct_k)\n",
        "\n",
        "  top1 = torch.cat(correct).mean()\n",
        "\n",
        "  return torch.tensor(losses).mean().item(), top1.mean().item()\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        acc = []\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float()\n",
        "            acc.append(correct_k)            \n",
        "            res.append(correct_k.sum(0, keepdim=True).mul_(100.0 / batch_size))\n",
        "        return res, acc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHs2bHb05wnt"
      },
      "source": [
        "## Finally, the main function\n",
        "\n",
        "This function runs the train/validate funciton for N epochs (how ever many you want). One epoch is a \"full pass\" through the entire training set, updating weights & biases after each mini-batch of data. At the end of each epoch, we also test the model on \"held out validation data\" to make sure we aren't over-learning idiosyncracies of the training set (we want our model to generalize to new data!)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjPW7CSZpsww"
      },
      "source": [
        "#required\n",
        "from fastprogress.fastprogress import master_bar, progress_bar \n",
        "\n",
        "def train_model(num_epochs):\n",
        "  mb = master_bar( range(num_epochs) )\n",
        "  mb.names = ['train_loss', 'val_loss']\n",
        "  xs,y1,y2 = [], [], []\n",
        "  for epoch in mb:\n",
        "    train_loss = train(model, train_loader, criterion, optimizer, mb=mb)\n",
        "    val_loss, top1 = validate(model, test_loader, criterion, optimizer, mb=mb)\n",
        "    # print(f\"Epoch {epoch}: Train Loss {train_loss}, Val Loss {val_loss} Top1 {top1}\")\n",
        "\n",
        "    # graph results\n",
        "    xs.append(epoch)\n",
        "    y1.append(train_loss)\n",
        "    y2.append(val_loss)\n",
        "    graphs = [[xs,y1], [xs,y2]]\n",
        "    x_bounds = [0, num_epochs]\n",
        "    y_bounds = [0,max(max(y1),max(y2))*1.1]\n",
        "    mb.update_graph(graphs, x_bounds, y_bounds)\n",
        "  print(\"All Done!\")\n",
        "  print(f\"Epoch {epoch}: Train Loss {train_loss:3.3f}, Val Loss {val_loss:3.3f} Top1 {top1:3.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuLjvO-I6W_J"
      },
      "source": [
        "# Exercise 1 - Train the Model to Recognize Digits!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5-tbLbK7A4G"
      },
      "source": [
        "# create a fresh instance of our model\n",
        "model = MyNet()\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0mehlE6sXxF"
      },
      "source": [
        "show_weights(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh-3X6Y67M8p"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=.03)\n",
        "train_model(num_epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiQ3Yx2p7Otf"
      },
      "source": [
        "show_weights(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlt2N1_0ptPT"
      },
      "source": [
        "## Exercise 2 - Improve your Model by training longer (e.g., 30 epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sorjd1C-AcHF"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONxxc8R0nJ6t"
      },
      "source": [
        "model = MyNet()\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7ThkbLynKdk"
      },
      "source": [
        "show_weights(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcimAPEU_uNA"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=.03)\n",
        "train_model(num_epochs=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUTSZr3xnC-W"
      },
      "source": [
        "show_weights(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VksX0TAM-gs8"
      },
      "source": [
        "## Exercise 2 - Improve your Model by using a better optimizer (e.g., Adam, Adadelta), or by varying the learning rate, or both; \n",
        "\n",
        "Save a record of the results for each variant you try (you can just create a new +Code cell for each run).\n",
        "\n",
        "SGD is known to show the \"best generalization\" but can also take longer. Adam and Adadelta are adaptive (intelligently adjust the step size), but Adam is known to have poorer generalization. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb9vC7nPBYV6"
      },
      "source": [
        "model = MyNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=.03)\n",
        "#optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0)\n",
        "train_model(num_epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI4Cqv7LHe61"
      },
      "source": [
        "show_weights(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI9eMmIgpkVn"
      },
      "source": [
        "# let's try Adam with a higher learning rate (matching the default for Adadelta)\n",
        "model = MyNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1.0)\n",
        "#optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0)\n",
        "train_model(num_epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5VXOwAs9Iwk"
      },
      "source": [
        "show_weights(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8fo-yOHpog4"
      },
      "source": [
        "# let's try Adam with a higher learning rate\n",
        "model = MyNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=1.0)\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0)\n",
        "train_model(num_epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_fNR6ukqPoO"
      },
      "source": [
        "show_weights(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiizSusb8K74"
      },
      "source": [
        "Compare the output weights (the visualizations) for SGD (exercise one), Adam, and Adadelta. What do you notice?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XfCU5bv-4gW"
      },
      "source": [
        "## Exercise 3 - Improve your Model by adding one or more hidden layers, with or without ReLU activations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPOz9jsfCJ7B"
      },
      "source": [
        "class MyShallowNet(nn.Module):\n",
        "  def __init__(self, use_relu=True):\n",
        "    super(MyShallowNet, self).__init__()\n",
        "    self.use_relu = use_relu\n",
        "    # in_features = 784, because the input image is 1x28x28 = 784\n",
        "    # out_features = 128, because there are 10 output categories (digits 0-9)\n",
        "    self.fc = nn.Linear(in_features=784, out_features=128)\n",
        "    if self.use_relu:\n",
        "      self.relu1 = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(in_features=128, out_features=10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # in the \"forward pass\", we take an input (a batch of images, x)\n",
        "    # then first we flatten it into batchSize x 784, \n",
        "    batchSize = x.shape[0] # first dimension of x is \"batchSize\"\n",
        "    x = x.view(batchSize, -1) # the -1 tells pytorch to flatten the tensor to be batchSize x \"whatever size fits\"\n",
        "    \n",
        "    x = self.fc(x)\n",
        "    if self.use_relu:\n",
        "      x = self.relu1(x)\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0jjRNvqrk8m"
      },
      "source": [
        "model = MyShallowNet()\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brrGoFk2rq_I"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0)\n",
        "train_model(num_epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDXdOQuhrx1H"
      },
      "source": [
        "show_weights(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAdbxy-_szPu"
      },
      "source": [
        "model = MyShallowNet(use_relu=False)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WotiwYX4s6Wr"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0)\n",
        "train_model(num_epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TcU3j21s9Np"
      },
      "source": [
        "class MyDeepNet(nn.Module):\n",
        "  def __init__(self, use_relu=True, use_dropout=True):\n",
        "    super(MyDeepNet, self).__init__()\n",
        "    self.use_relu = use_relu\n",
        "    self.use_dropout = use_dropout\n",
        "\n",
        "    # in_features = 784, because the input image is 1x28x28 = 784\n",
        "    # out_features = 128, because there are 10 output categories (digits 0-9)\n",
        "    self.fc = nn.Linear(in_features=784, out_features=128)\n",
        "    if self.use_relu:\n",
        "      self.relu1 = nn.ReLU()\n",
        "    \n",
        "    if self.use_dropout:\n",
        "      self.dropout1 = nn.Dropout2d(0.50)\n",
        "\n",
        "    self.fc2 = nn.Linear(in_features=128, out_features=128)\n",
        "    if self.use_relu:\n",
        "      self.relu2 = nn.ReLU()\n",
        "    \n",
        "    if self.use_dropout:\n",
        "      self.dropout2 = nn.Dropout2d(0.50)\n",
        "\n",
        "    self.fc3 = nn.Linear(in_features=128, out_features=10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # in the \"forward pass\", we take an input (a batch of images, x)\n",
        "    # then first we flatten it into batchSize x 784, \n",
        "    batchSize = x.shape[0] # first dimension of x is \"batchSize\"\n",
        "    x = x.view(batchSize, -1) # the -1 tells pytorch to flatten the tensor to be batchSize x \"whatever size fits\"\n",
        "    \n",
        "    x = self.fc(x)\n",
        "    if self.use_relu:\n",
        "      x = self.relu1(x)\n",
        "    \n",
        "    if self.use_dropout:\n",
        "      x = self.dropout1(x)\n",
        "\n",
        "    x = self.fc2(x)\n",
        "    if self.use_relu:\n",
        "      x = self.relu2(x)\n",
        "\n",
        "    if self.use_dropout:\n",
        "      x = self.dropout2(x)\n",
        "\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgBl_NWBtoAQ"
      },
      "source": [
        "model = MyDeepNet(use_relu=True, use_dropout=True)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf1H9nIPtoD1"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0)\n",
        "train_model(num_epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOXoDTJKCoxv"
      },
      "source": [
        "show_weights(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XcIWaqY9wXt"
      },
      "source": [
        "# your turn. Two of us try without relu, two without dropout, two without both. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvan8oFnZgar"
      },
      "source": [
        "model = MyDeepNet(use_relu=False, use_dropout=True)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgXGSrxkcMWq"
      },
      "source": [
        "## gather measures from everyone to plot a graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7XT2ayYZosT"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.DataFrame(columns=['model_name','relu','dropout','train_loss','val_loss','top1'])\n",
        "scores = [\n",
        "  (True, True, 0.14, 0.09, 0.97),\n",
        "]\n",
        "for relu,dropout,train_loss,val_loss,top1 in scores:\n",
        "  model_name = f'relu{relu}_dropout{dropout}'\n",
        "  df = df.append({\n",
        "      \"model_name\": model_name,\n",
        "      \"relu\": relu,\n",
        "      \"dropout\": dropout,\n",
        "      \"train_loss\": train_loss,\n",
        "      \"val_loss\": val_loss,\n",
        "      \"top1\": top1,\n",
        "  }, ignore_index=True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBl4bfctb9l2"
      },
      "source": [
        "ax = sns.barplot(data=df, x=\"relu\", y=\"train_loss\", hue=\"dropout\", \n",
        "                 order=[True,False], hue_order=[True,False]); "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1d3u8agb9w9"
      },
      "source": [
        "ax = sns.barplot(data=df, x=\"relu\", y=\"val_loss\", hue=\"dropout\", \n",
        "                 order=[True,False], hue_order=[True,False]); "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdWI8lrJb96g"
      },
      "source": [
        "ax = sns.barplot(data=df, x=\"relu\", y=\"top1\", hue=\"dropout\", \n",
        "                 order=[True,False], hue_order=[True,False]); "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUw9zLJW_JyL"
      },
      "source": [
        "## Exercise 4 - Improve your Model by using convolutional layers\n",
        "\n",
        "Save a record of the results for each variant you try."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESvsaVBfCVmr"
      },
      "source": [
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "# reference: https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.cnn_backbone = nn.Sequential(OrderedDict([\n",
        "             ('conv1', nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)),\n",
        "             ('relu1', nn.ReLU()),\n",
        "             ('conv2', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)),\n",
        "             ('relu2', nn.ReLU()),\n",
        "             ('pool2', nn.MaxPool2d(2)),\n",
        "             ('dropout2', nn.Dropout2d(0.25))\n",
        "        ]))\n",
        "        self.head = nn.Sequential(OrderedDict([\n",
        "            ('fc3', nn.Linear(9216, 128)),\n",
        "            ('relu3', nn.ReLU()),\n",
        "            ('dropout3', nn.Dropout2d(0.50)),\n",
        "            ('fc4', nn.Linear(128, 10)),\n",
        "            ('relu4', nn.ReLU()),\n",
        "        ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn_backbone(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.head(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO1Dz_mtyw8o"
      },
      "source": [
        "model = CNN()\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqzdIKdXPWlF"
      },
      "source": [
        "fake_imgs = torch.rand(10,1,28,28)\n",
        "out = model(fake_imgs)\n",
        "out.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMOvuV3fCcia"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=.03)\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0)\n",
        "train_model(num_epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCZWbr4hxe6v"
      },
      "source": [
        "show_weights(model.cnn_backbone.conv1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tHUn6Lm_UyR"
      },
      "source": [
        "## Exercise 5 - Challenge your model by adding position and scale variation, see how this affects learning, test performance.\n",
        "\n",
        "If you get an \"out of memory\" error, you might have to goto \"Runtime\" => \"Restart runtime\". However, after you restart a runtime, everything is wiped from memory, include functions like \"train_model\" which are annoyingly scattered throughout this notebook.\n",
        "\n",
        "So you have to go back and reload the functions needed to train a model. I've added the text \"#required\" to the start of any cell that's needed to train a model, so that you can find them and just execute those cells (skipping all the excercises interspersed). So, press command+f to find text, and search for \"#required\", then for each of those cells press \"shift + enter\" to execute it. \n",
        "\n",
        "BUT WAIT. Why did we run out of memory? Could be a bunch of other variables that you don't need hogging GPU space. It could be that your current model is TOO BIG to fit on the GPU, or your images are too large, or you are trying to run too many of them through the model at once.\n",
        "\n",
        "So, how do you trouble shoot? Try the following, in order, but remember to restart the runtime and run #required cells before each troubleshooting step:\n",
        "- just restart and try again (don't change your model or training code): restart runtime, load only the required cells and anything you need for your new model\n",
        "- try reducing your batch size (but if this get's below 64, you'll run into issues due to small batch size)\n",
        "- try reducing the input image size\n",
        "- try reducing your model size\n",
        "- buy a bigger GPU\n",
        "- Pay Amazon or Google to rent their bigger GPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL2_JBz_0a6m"
      },
      "source": [
        "#required\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.transforms.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "\n",
        "def random_size(img, sizes=[28,56,128]):\n",
        "  s = np.random.choice(sizes)\n",
        "  return F.resize(img, (s, s))\n",
        "\n",
        "def embed_image_centered(img, bg_size=(224,224)):\n",
        "  img_w, img_h = img.size\n",
        "  background = Image.new('L', bg_size, color=0)\n",
        "  bg_w, bg_h = background.size\n",
        "  # centered, but we want to randomly position\n",
        "  offset = ((bg_w - img_w) // 2, (bg_h - img_h) // 2)\n",
        "  background.paste(img, offset)\n",
        "  return background  \n",
        "\n",
        "def embed_image_random(img, bg_size=(224,224)):\n",
        "  img_w, img_h = img.size\n",
        "  background = Image.new('L', bg_size, color=0)\n",
        "  bg_w, bg_h = background.size\n",
        "  h_shift = (bg_w - img_w) * np.random.rand()\n",
        "  v_shift = (bg_h - img_h) * np.random.rand()\n",
        "  offset = (int(h_shift), int(v_shift))\n",
        "  background.paste(img, offset)\n",
        "  return background  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPAp-MPz20Dj"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "  random_size,\n",
        "  embed_image_random,\n",
        "  transforms.ToTensor(),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaKMC1Gh4pKL"
      },
      "source": [
        "train_dataset = datasets.MNIST('./data/MNIST', train=True, download=True, transform=transform)\n",
        "train_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlUMWeuQ4qhl"
      },
      "source": [
        "train_dataset[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scI-OLpz4uj6"
      },
      "source": [
        "test_dataset = datasets.MNIST('./data/MNIST', train=False, download=True, transform=transform)\n",
        "test_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5zz-8HK41XX"
      },
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=200, \n",
        "                          num_workers=4, pin_memory=True, shuffle=True)\n",
        "train_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6tcyZBI6UiY"
      },
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=200, \n",
        "                         num_workers=4, pin_memory=True, shuffle=True)\n",
        "test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxdpBM0eO6hB"
      },
      "source": [
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "# reference: https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "class CNN_224(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_224, self).__init__()\n",
        "        self.cnn_backbone = nn.Sequential(OrderedDict([\n",
        "             ('conv1', nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)),\n",
        "             ('relu1', nn.ReLU()),\n",
        "             ('pool1', nn.MaxPool2d(2)),\n",
        "             ('conv2', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)),\n",
        "             ('relu2', nn.ReLU()),\n",
        "             ('pool2', nn.MaxPool2d(2)),\n",
        "             ('dropout2', nn.Dropout2d(0.25)),             \n",
        "        ]))\n",
        "        self.downsample = nn.AdaptiveAvgPool2d((6,6))\n",
        "        self.head = nn.Sequential(OrderedDict([\n",
        "            ('fc3', nn.Linear(64*6*6, 128)),\n",
        "            ('relu3', nn.ReLU()),\n",
        "            ('dropout3', nn.Dropout2d(0.50)),\n",
        "            ('fc4', nn.Linear(128, 10)),\n",
        "            ('relu4', nn.ReLU()),\n",
        "        ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn_backbone(x)\n",
        "        x = self.downsample(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.head(x)\n",
        "        return x        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycJDFQcE6YpO"
      },
      "source": [
        "model = CNN_224()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=.03)\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0)\n",
        "train_model(num_epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf6Dkyxt6lr5"
      },
      "source": [
        "train_model(num_epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIfIcLMGgocU"
      },
      "source": [
        "train_model(num_epochs=70)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHUaMx_tdHn2"
      },
      "source": [
        "## Bonus Exercises\n",
        "\n",
        "Experiment with varying the kernel_size, or out_channels of different layers in your network. Use our default settings above as your \"baseline\". Then only adjust one parameter at a time, so you can isolate which factor accounts for any changes in performance (if you change two things, you have no way of knowing which one \"caused\" the change in performance). Try visualizing your kernels (whether you vary kernel_size or out_channels) to see whether the tuning functions change in any obvious way. Once you have a sense for how individual parameters affect your model, you can experiment with more dramatic changes (changing multiple parameters at once). \n",
        "\n",
        "Coordinate with each other if you would like to collate results (since it takes a while to run even one model!).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9hUHCIOdELB"
      },
      "source": [
        ""
      ]
    }
  ]
}