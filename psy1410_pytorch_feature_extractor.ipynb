{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "psy1410_pytorch_feature_extractor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBJ1wRQkQJ+zzGEgSkGCPI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harvard-visionlab/psy1410/blob/master/psy1410_pytorch_feature_extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMzEei4I2l6f"
      },
      "source": [
        "'''\n",
        "    FeatureExtractor class that allows you to retain outputs of any layer.\n",
        "    \n",
        "    This class uses PyTorch's \"forward hooks\", which let you insert a function\n",
        "    that takes the input and output of a module as arguements.\n",
        "    \n",
        "    In this hook function you can insert tasks like storing the intermediate values,\n",
        "    or as we'll do in the FeatureEditor class, actually modify the outputs.\n",
        "    \n",
        "    Adding these hooks can cause headaches if you don't \"remove\" them \n",
        "    after you are done with them. For this reason, the FeatureExtractor is \n",
        "    setup to be used as a context, which sets up the hooks when\n",
        "    you enter the context, and removes them when you leave:\n",
        "    \n",
        "    with FeatureExtractor(model, layer_name) as extractor:\n",
        "        features = extractor(imgs)\n",
        "    \n",
        "    If there's an error in that context (or you cancel the operation),\n",
        "    the __exit__ function of the feature extractor is executed,\n",
        "    which we've setup to remove the hooks. This will save you \n",
        "    headaches during debugging/development.\n",
        "    \n",
        "'''\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, model, layers, detach=True, clone=True, device='cpu'):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.layers = [layers] if isinstance(layers, str) else layers\n",
        "        self.detach = detach\n",
        "        self.clone = clone\n",
        "        self.device = device\n",
        "        self._features = {layer: torch.empty(0) for layer in layers}        \n",
        "        self.hooks = {}\n",
        "        \n",
        "    def hook_layers(self):        \n",
        "        self.remove_hooks()\n",
        "        for layer_id in self.layers:\n",
        "            layer = dict([*self.model.named_modules()])[layer_id]\n",
        "            self.hooks[layer_id] = layer.register_forward_hook(self.save_outputs_hook(layer_id))\n",
        "    \n",
        "    def remove_hooks(self):\n",
        "        for layer_id in self.layers:\n",
        "            self._features[layer_id] = torch.empty(0)\n",
        "            if layer_id in self.hooks:\n",
        "                self.hooks[layer_id].remove()\n",
        "                del self.hooks[layer_id]\n",
        "    \n",
        "    def __enter__(self, *args): \n",
        "        self.hook_layers()\n",
        "        return self\n",
        "    \n",
        "    def __exit__(self, *args): \n",
        "        self.remove_hooks()\n",
        "        \n",
        "    def save_outputs_hook(self, layer_id):\n",
        "        def fn(_, __, output):\n",
        "            if self.detach: output = output.detach()\n",
        "            if self.clone: output = output.clone()\n",
        "            if self.device: output = output.to(self.device)\n",
        "            self._features[layer_id] = output\n",
        "        return fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        _ = self.model(x)\n",
        "        return self._features\n",
        "    \n",
        "def get_layers(model, parent_name='', layer_info=[]):\n",
        "    for module_name, module in model.named_children():\n",
        "        layer_name = parent_name + '.' + module_name\n",
        "        if len(list(module.named_children())):\n",
        "            layer_info = get_layers(module, layer_name, layer_info=layer_info)\n",
        "        else:\n",
        "            layer_info.append(layer_name.strip('.'))\n",
        "    \n",
        "    return layer_info\n",
        "\n",
        "def get_layer(m, layers):\n",
        "    layer = layers.pop(0)\n",
        "    m = getattr(m, layer)\n",
        "    if len(layers) > 0:\n",
        "        return get_layer(m, layers)\n",
        "    return m\n",
        "\n",
        "def get_layer_type(model, layer_name):\n",
        "    m = get_layer(model, layer_name.split(\".\"))\n",
        "    return m.__class__.__name__\n",
        "            \n",
        "def convert_relu_layers(parent):\n",
        "    for child_name, child in parent.named_children():\n",
        "        if isinstance(child, nn.ReLU) and child.inplace==True:\n",
        "            setattr(parent, child_name, nn.ReLU(inplace=False))\n",
        "        elif len(list(child.children())) > 0:\n",
        "            convert_relu_layers(child)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}